{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "0tAGJPoeKrfI"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Anna\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загружаем данные\n",
    "df = pd.read_csv('data/FlightData.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "del_columns = ['timestamp', 'time', 'localtime']\n",
    "\n",
    "# Используйте метод drop для удаления столбцов\n",
    "df.drop(del_columns, axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Набор данных состоит из 187654 записей и 7 признаков.\n",
    "\n",
    "Целевая переменная была вычислена как евклидово расстояние между значениями вертикального и горизонтального отклонения от глиссады."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# объединяем вертикальное и горизонтальное отклонения в один показатель\n",
    "df['Glidepath deviation'] = np.sqrt(df['Vertical']**2 + df['Horizontal']**2)\n",
    "\n",
    "#df['Glidepath deviation'] = np.arctan2(df['Vertical'], df['Horizontal'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 187654 entries, 0 to 187653\n",
      "Data columns (total 12 columns):\n",
      " #   Column                 Non-Null Count   Dtype  \n",
      "---  ------                 --------------   -----  \n",
      " 0   Roll                   187654 non-null  float64\n",
      " 1   Pitch                  187654 non-null  float64\n",
      " 2   Angle                  187654 non-null  float64\n",
      " 3   Heading                187654 non-null  float64\n",
      " 4   Altitude               187654 non-null  float64\n",
      " 5   Vertical               187654 non-null  float64\n",
      " 6   Horizontal             187654 non-null  float64\n",
      " 7   Right Sidestick pitch  187654 non-null  float64\n",
      " 8   Right Sidestick roll   187654 non-null  float64\n",
      " 9   FPG                    187654 non-null  float64\n",
      " 10  KGR                    187654 non-null  float64\n",
      " 11  Glidepath deviation    187654 non-null  float64\n",
      "dtypes: float64(12)\n",
      "memory usage: 17.2 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# удаляем вертикальное и горизонтальное отклонения, а также ненужные столбцы\n",
    "columns_to_drop = [\"Vertical\", \"Horizontal\",\"Altitude\", \"KGR\"]  \n",
    "df.drop(columns=columns_to_drop, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jq0D9_A1VSV9"
   },
   "source": [
    "# Собираем датасет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Разбиваем датасет на X и y\n",
    "X = df.drop([\"Glidepath deviation\"], axis=1)\n",
    "y = df[\"Glidepath deviation\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Так как данных много, то для тренировочного набора было взято 85%, а для валидационного и тестового по 7,5%.\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Разбиваем данные на train, test, val.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.15, random_state = 0)\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_test, y_test, test_size = 0.5, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Метод масштабирования MinMaxScaler приводит значения признаков к интервалу [0, 1] или другому заданному интервалу. Так как многие признаки изменяются в небольших значениях и находятся в окрестности 0, то использование MinMaxScaler может привести к схожести между loss и val_loss.\n",
    "\n",
    "Поэтому выбран метод StandardScaler, который центрирует данные (делает их средним равным 0) и масштабирует их так, чтобы стандартное отклонение было равно 1. Это более общий метод масштабирования, который может сохранить более широкий диапазон значений, что может предотвратить схожесть между loss и val_loss.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scaler = MinMaxScaler()\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "X_val = scaler.transform(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((159505, 7), (14074, 7), (14075, 7))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape, X_val.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Создаем модель"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Функция активации – Relu, которая быстро вычисляется и помогает избежать проблемы исчезающего градиента\n",
    ".\r\n",
    "Используется оптимизатор Nadam. В данной задаче путём обучения модели с разными параметрами, было выяснено, что данный оптимизатор подошёл лучше, чем Adam или SGD. Скорость обучения установлена равной 0.005, количество эпох – 700 (при этих значениях скорости модель ещё сходилась)\n",
    ". \r\n",
    "В качестве функции потерь выбрана Log-Cosh, так как она подходит для регрессии и менее чувствительна к выбросам, чем MSE.\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Anna\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "inputs = tf.keras.layers.Input(shape=X_train.shape[1], name='input')\n",
    "x_1 = tf.keras.layers.Dense(units=32, activation='relu',  name='dense_1')(inputs)\n",
    "output = tf.keras.layers.Dense(units=1, activation='relu', name='output') (x_1)\n",
    "\n",
    "#x_1 = tf.keras.layers.Dense(units=32, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01), name='dense_1')(inputs)\n",
    "\n",
    "\n",
    "model = tf.keras.Model(inputs=inputs, outputs=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Anna\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "inputs = tf.keras.layers.Input(shape=X_train.shape[1], name='input')\n",
    "x_1 = tf.keras.layers.Dense(units=32, activation='relu',  name='dense_1')(inputs)\n",
    "x_2 = tf.keras.layers.Dense(units=8, activation='relu', name='dense_2')(x_1)\n",
    "output = tf.keras.layers.Dense(units=1, activation='relu', name='output') (x_2)\n",
    "\n",
    "model2 = tf.keras.Model(inputs=inputs, outputs=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tf.keras.layers.Input(shape=X_train.shape[1], name='input')\n",
    "x_1 = tf.keras.layers.Dense(units=32, activation='relu',  name='dense_1')(inputs)\n",
    "output = tf.keras.layers.Dense(units=1, activation='relu', name='output') (x_1)\n",
    "\n",
    "#x_1 = tf.keras.layers.Dense(units=32, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01), name='dense_1')(inputs)\n",
    "\n",
    "\n",
    "model3 = tf.keras.Model(inputs=inputs, outputs=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Anna\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "inputs = tf.keras.layers.Input(shape=X_train.shape[1], name='input')\n",
    "#x_1 = tf.keras.layers.Dense(units=32, activation='relu',  name='dense_1')(inputs)\n",
    "x_1 = tf.keras.layers.Dense(units=32, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01), name='dense_1')(inputs)\n",
    "output = tf.keras.layers.Dense(units=1, activation='relu', name='output') (x_1)\n",
    "\n",
    "model4 = tf.keras.Model(inputs=inputs, outputs=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input (InputLayer)          [(None, 7)]               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 32)                256       \n",
      "                                                                 \n",
      " output (Dense)              (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 289 (1.13 KB)\n",
      "Trainable params: 289 (1.13 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input (InputLayer)          [(None, 7)]               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 32)                256       \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 8)                 264       \n",
      "                                                                 \n",
      " output (Dense)              (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 529 (2.07 KB)\n",
      "Trainable params: 529 (2.07 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input (InputLayer)          [(None, 7)]               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 32)                256       \n",
      "                                                                 \n",
      " output (Dense)              (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 289 (1.13 KB)\n",
      "Trainable params: 289 (1.13 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input (InputLayer)          [(None, 7)]               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 32)                256       \n",
      "                                                                 \n",
      " output (Dense)              (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 289 (1.13 KB)\n",
      "Trainable params: 289 (1.13 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model4.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Обучение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Nadam(learning_rate=0.005), \n",
    "    loss = tf.keras.losses.LogCosh()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.compile(\n",
    "    optimizer=tf.keras.optimizers.Nadam(learning_rate=0.005), \n",
    "    loss = tf.keras.losses.LogCosh()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3.compile(\n",
    "    optimizer=tf.keras.optimizers.Nadam(learning_rate=0.005), \n",
    "    loss = tf.keras.losses.Huber(delta=3.0)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/700\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0038 - val_loss: 0.0056\n",
      "Epoch 2/700\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0055 - val_loss: 0.0045\n",
      "Epoch 3/700\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 4/700\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0042 - val_loss: 0.0041\n",
      "Epoch 5/700\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0040 - val_loss: 0.0040\n",
      "Epoch 6/700\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0039 - val_loss: 0.0040\n",
      "Epoch 7/700\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0039 - val_loss: 0.0040\n",
      "Epoch 8/700\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0040 - val_loss: 0.0042\n",
      "Epoch 9/700\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0041 - val_loss: 0.0041\n",
      "Epoch 10/700\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0040 - val_loss: 0.0042\n",
      "Epoch 11/700\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0041 - val_loss: 0.0041\n",
      "Epoch 12/700\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0040 - val_loss: 0.0041\n",
      "Epoch 13/700\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0040 - val_loss: 0.0040\n",
      "Epoch 14/700\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0039 - val_loss: 0.0040\n",
      "Epoch 15/700\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0039 - val_loss: 0.0040\n",
      "Epoch 16/700\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0039 - val_loss: 0.0040\n",
      "Epoch 17/700\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 18/700\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 19/700\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 20/700\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 21/700\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 22/700\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 23/700\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 24/700\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 25/700\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 26/700\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 27/700\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 28/700\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 29/700\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 30/700\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 31/700\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 32/700\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 33/700\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 34/700\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 35/700\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 36/700\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 37/700\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 38/700\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 39/700\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 40/700\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 41/700\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 42/700\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 43/700\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 44/700\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 45/700\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 46/700\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 47/700\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 48/700\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 49/700\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 50/700\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 51/700\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 52/700\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 53/700\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 54/700\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 55/700\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 56/700\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 57/700\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 58/700\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 59/700\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 60/700\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 61/700\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 62/700\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 63/700\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 64/700\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 65/700\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 66/700\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 67/700\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 68/700\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 69/700\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 70/700\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 71/700\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 72/700\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 73/700\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 74/700\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 75/700\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 76/700\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 77/700\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 78/700\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 79/700\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 80/700\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 81/700\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 82/700\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 83/700\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 84/700\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 85/700\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 86/700\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 87/700\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 88/700\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 89/700\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 90/700\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 91/700\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 92/700\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 93/700\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 94/700\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 95/700\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 96/700\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 97/700\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 98/700\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 99/700\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 100/700\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 101/700\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 102/700\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 103/700\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 104/700\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 105/700\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 106/700\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 107/700\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 108/700\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 109/700\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 110/700\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 111/700\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 112/700\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 113/700\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 114/700\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 115/700\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 116/700\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 117/700\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 118/700\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 119/700\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 120/700\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 121/700\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 122/700\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 123/700\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 124/700\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 125/700\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 126/700\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 127/700\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 128/700\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 129/700\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 130/700\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 131/700\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 132/700\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 133/700\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 134/700\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 135/700\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 136/700\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 137/700\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 138/700\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 139/700\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 140/700\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 141/700\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 142/700\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 143/700\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 144/700\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 145/700\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 146/700\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 147/700\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 148/700\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0038 - val_loss: 0.0040\n",
      "Epoch 149/700\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 150/700\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0038 - val_loss: 0.0040\n",
      "Epoch 151/700\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 152/700\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0038 - val_loss: 0.0040\n",
      "Epoch 153/700\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 154/700\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 155/700\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 156/700\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 157/700\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 158/700\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 159/700\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 160/700\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 161/700\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 162/700\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 163/700\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 164/700\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 165/700\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 166/700\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 167/700\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 168/700\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 169/700\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 170/700\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 171/700\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 172/700\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 173/700\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 174/700\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 175/700\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 176/700\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 177/700\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 178/700\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 179/700\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 180/700\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 181/700\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 182/700\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 183/700\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 184/700\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 185/700\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 186/700\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 187/700\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 188/700\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 189/700\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 190/700\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 191/700\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 192/700\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 193/700\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 194/700\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 195/700\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 196/700\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 197/700\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 198/700\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 199/700\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 200/700\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 201/700\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 202/700\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 203/700\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 204/700\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 205/700\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 206/700\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 207/700\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 208/700\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 209/700\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 210/700\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 211/700\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 212/700\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 213/700\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 214/700\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 215/700\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 216/700\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 217/700\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 218/700\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 219/700\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 220/700\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 221/700\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 222/700\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 223/700\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 224/700\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 225/700\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 226/700\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 227/700\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 228/700\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 229/700\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 230/700\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 231/700\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 232/700\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 233/700\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 234/700\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 235/700\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 236/700\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 237/700\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 238/700\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 239/700\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 240/700\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 241/700\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 242/700\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 243/700\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 244/700\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 245/700\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 246/700\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 247/700\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 248/700\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 249/700\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 250/700\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 251/700\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 252/700\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 253/700\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 254/700\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 255/700\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 256/700\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 257/700\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 258/700\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 259/700\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 260/700\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 261/700\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 262/700\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 263/700\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 264/700\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 265/700\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 266/700\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 267/700\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 268/700\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 269/700\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 270/700\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 271/700\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 272/700\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 273/700\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 274/700\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 275/700\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 276/700\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 277/700\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 278/700\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 279/700\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 280/700\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 281/700\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 282/700\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 283/700\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 284/700\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 285/700\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 286/700\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 287/700\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 288/700\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 289/700\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 290/700\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 291/700\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 292/700\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 293/700\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 294/700\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 295/700\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 296/700\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 297/700\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 298/700\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 299/700\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 300/700\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 301/700\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 302/700\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 303/700\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 304/700\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 305/700\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 306/700\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 307/700\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 308/700\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 309/700\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 310/700\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 311/700\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 312/700\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 313/700\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 314/700\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 315/700\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 316/700\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 317/700\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 318/700\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 319/700\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 320/700\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 321/700\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 322/700\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 323/700\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 324/700\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 325/700\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 326/700\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 327/700\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 328/700\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 329/700\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 330/700\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0038 - val_loss: 0.0038\n",
      "Epoch 331/700\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 332/700\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0038 - val_loss: 0.0038\n",
      "Epoch 333/700\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 334/700\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 335/700\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 336/700\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 337/700\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 338/700\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 339/700\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 340/700\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 341/700\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 342/700\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 343/700\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 344/700\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 345/700\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 346/700\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 347/700\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 348/700\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 349/700\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 350/700\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 351/700\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 352/700\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 353/700\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 354/700\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 355/700\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 356/700\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 357/700\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 358/700\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 359/700\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 360/700\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 361/700\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 362/700\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 363/700\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 364/700\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 365/700\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 366/700\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 367/700\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 368/700\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 369/700\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 370/700\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0038 - val_loss: 0.0038\n",
      "Epoch 371/700\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 372/700\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0038 - val_loss: 0.0038\n",
      "Epoch 373/700\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 374/700\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0038 - val_loss: 0.0038\n",
      "Epoch 375/700\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 376/700\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0038 - val_loss: 0.0038\n",
      "Epoch 377/700\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0037 - val_loss: 0.0039\n",
      "Epoch 378/700\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0038 - val_loss: 0.0038\n",
      "Epoch 379/700\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0037 - val_loss: 0.0039\n",
      "Epoch 380/700\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0038 - val_loss: 0.0038\n",
      "Epoch 381/700\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0037 - val_loss: 0.0039\n",
      "Epoch 382/700\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0038 - val_loss: 0.0038\n",
      "Epoch 383/700\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0037 - val_loss: 0.0039\n",
      "Epoch 384/700\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0038 - val_loss: 0.0038\n",
      "Epoch 385/700\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 386/700\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0038 - val_loss: 0.0038\n",
      "Epoch 387/700\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 388/700\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0038 - val_loss: 0.0038\n",
      "Epoch 389/700\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 390/700\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0038 - val_loss: 0.0038\n",
      "Epoch 391/700\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 392/700\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0038 - val_loss: 0.0038\n",
      "Epoch 393/700\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 394/700\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 395/700\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 396/700\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 397/700\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 398/700\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 399/700\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 400/700\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 401/700\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 402/700\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 403/700\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 404/700\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 405/700\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 406/700\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 407/700\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 408/700\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 409/700\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 410/700\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 411/700\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 412/700\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 413/700\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 414/700\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 415/700\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 416/700\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 417/700\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 418/700\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 419/700\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 420/700\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0038 - val_loss: 0.0038\n",
      "Epoch 421/700\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 422/700\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 423/700\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 424/700\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 425/700\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 426/700\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 427/700\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 428/700\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 429/700\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 430/700\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0038 - val_loss: 0.0038\n",
      "Epoch 431/700\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 432/700\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0038 - val_loss: 0.0038\n",
      "Epoch 433/700\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 434/700\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0038 - val_loss: 0.0038\n",
      "Epoch 435/700\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 436/700\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0038 - val_loss: 0.0038\n",
      "Epoch 437/700\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0037 - val_loss: 0.0039\n",
      "Epoch 438/700\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0038 - val_loss: 0.0038\n",
      "Epoch 439/700\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 440/700\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0038 - val_loss: 0.0038\n",
      "Epoch 441/700\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 442/700\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0038 - val_loss: 0.0038\n",
      "Epoch 443/700\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 444/700\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0038 - val_loss: 0.0038\n",
      "Epoch 445/700\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 446/700\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0038 - val_loss: 0.0038\n",
      "Epoch 447/700\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 448/700\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 449/700\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 450/700\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 451/700\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 452/700\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 453/700\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 454/700\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 455/700\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 456/700\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 457/700\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 458/700\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 459/700\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 460/700\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 461/700\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 462/700\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 463/700\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 464/700\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0038 - val_loss: 0.0038\n",
      "Epoch 465/700\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 466/700\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0038 - val_loss: 0.0038\n",
      "Epoch 467/700\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 468/700\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0038 - val_loss: 0.0038\n",
      "Epoch 469/700\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 470/700\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 471/700\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 472/700\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 473/700\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 474/700\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 475/700\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 476/700\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 477/700\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 478/700\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 479/700\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 480/700\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 481/700\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 482/700\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 483/700\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0038 - val_loss: 0.0038\n",
      "Epoch 484/700\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 485/700\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0038 - val_loss: 0.0038\n",
      "Epoch 486/700\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 487/700\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0038 - val_loss: 0.0038\n",
      "Epoch 488/700\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 489/700\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 490/700\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 491/700\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 492/700\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 493/700\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 494/700\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 495/700\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 496/700\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 497/700\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 498/700\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 499/700\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 500/700\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 501/700\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 502/700\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 503/700\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 504/700\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 505/700\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 506/700\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 507/700\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 508/700\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 509/700\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 510/700\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 511/700\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 512/700\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 513/700\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 514/700\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 515/700\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 516/700\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 517/700\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 518/700\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 519/700\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 520/700\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 521/700\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 522/700\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 523/700\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 524/700\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 525/700\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 526/700\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 527/700\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 528/700\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 529/700\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 530/700\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 531/700\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 532/700\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 533/700\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 534/700\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 535/700\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0038 - val_loss: 0.0038\n",
      "Epoch 536/700\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 537/700\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 538/700\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 539/700\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 540/700\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 541/700\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 542/700\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 543/700\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 544/700\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 545/700\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 546/700\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 547/700\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 548/700\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 549/700\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 550/700\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 551/700\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 552/700\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 553/700\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0038 - val_loss: 0.0038\n",
      "Epoch 554/700\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 555/700\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0038 - val_loss: 0.0038\n",
      "Epoch 556/700\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 557/700\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0038 - val_loss: 0.0038\n",
      "Epoch 558/700\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0038 - val_loss: 0.0038\n",
      "Epoch 559/700\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0038 - val_loss: 0.0038\n",
      "Epoch 560/700\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 561/700\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 562/700\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 563/700\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 564/700\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 565/700\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 566/700\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 567/700\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 568/700\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 569/700\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 570/700\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 571/700\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 572/700\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 573/700\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 574/700\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 575/700\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 576/700\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 577/700\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 578/700\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 579/700\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 580/700\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 581/700\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 582/700\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 583/700\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 584/700\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 585/700\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 586/700\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 587/700\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 588/700\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 589/700\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 590/700\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 591/700\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 592/700\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 593/700\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 594/700\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 595/700\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 596/700\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 597/700\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 598/700\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 599/700\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 600/700\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 601/700\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 602/700\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 603/700\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 604/700\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 605/700\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 606/700\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 607/700\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 608/700\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 609/700\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 610/700\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 611/700\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 612/700\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 613/700\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 614/700\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 615/700\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 616/700\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 617/700\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 618/700\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 619/700\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 620/700\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 621/700\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 622/700\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 623/700\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 624/700\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 625/700\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 626/700\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 627/700\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 628/700\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 629/700\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 630/700\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 631/700\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 632/700\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 633/700\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 634/700\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 635/700\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 636/700\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 637/700\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 638/700\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 639/700\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 640/700\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 641/700\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 642/700\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 643/700\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 644/700\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 645/700\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 646/700\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 647/700\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 648/700\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 649/700\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 650/700\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 651/700\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 652/700\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 653/700\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 654/700\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 655/700\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 656/700\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 657/700\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 658/700\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 659/700\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 660/700\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 661/700\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 662/700\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 663/700\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 664/700\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 665/700\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 666/700\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 667/700\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 668/700\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 669/700\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 670/700\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 671/700\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 672/700\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 673/700\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 674/700\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 675/700\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 676/700\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 677/700\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 678/700\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 679/700\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 680/700\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 681/700\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 682/700\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 683/700\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 684/700\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 685/700\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 686/700\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 687/700\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 688/700\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 689/700\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 690/700\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 691/700\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 692/700\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 693/700\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 694/700\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 695/700\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 696/700\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 697/700\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 698/700\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 699/700\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 700/700\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0037 - val_loss: 0.0038\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    x=X_train,\n",
    "    y=y_train,\n",
    "    batch_size=X_train.shape[0],\n",
    "    epochs=700,\n",
    "    validation_data=(X_val, y_val),\n",
    "    shuffle=False,\n",
    "    steps_per_epoch=1,\n",
    "    validation_steps=1,\n",
    "    validation_batch_size=X_val.shape[0]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/700\n",
      "WARNING:tensorflow:From C:\\Users\\Anna\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0364 - val_loss: 0.0239\n",
      "Epoch 2/700\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0237 - val_loss: 0.0181\n",
      "Epoch 3/700\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0180 - val_loss: 0.0142\n",
      "Epoch 4/700\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0140 - val_loss: 0.0117\n",
      "Epoch 5/700\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0115 - val_loss: 0.0101\n",
      "Epoch 6/700\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0099 - val_loss: 0.0092\n",
      "Epoch 7/700\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0090 - val_loss: 0.0087\n",
      "Epoch 8/700\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0085 - val_loss: 0.0084\n",
      "Epoch 9/700\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0083 - val_loss: 0.0083\n",
      "Epoch 10/700\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0082 - val_loss: 0.0083\n",
      "Epoch 11/700\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0082 - val_loss: 0.0083\n",
      "Epoch 12/700\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0082 - val_loss: 0.0083\n",
      "Epoch 13/700\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0081 - val_loss: 0.0082\n",
      "Epoch 14/700\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0081 - val_loss: 0.0082\n",
      "Epoch 15/700\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0081 - val_loss: 0.0081\n",
      "Epoch 16/700\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0080 - val_loss: 0.0081\n",
      "Epoch 17/700\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0080 - val_loss: 0.0080\n",
      "Epoch 18/700\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0079 - val_loss: 0.0079\n",
      "Epoch 19/700\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0078 - val_loss: 0.0079\n",
      "Epoch 20/700\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0078 - val_loss: 0.0078\n",
      "Epoch 21/700\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0077 - val_loss: 0.0078\n",
      "Epoch 22/700\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0077 - val_loss: 0.0077\n",
      "Epoch 23/700\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0077 - val_loss: 0.0077\n",
      "Epoch 24/700\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0076 - val_loss: 0.0076\n",
      "Epoch 25/700\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0076 - val_loss: 0.0075\n",
      "Epoch 26/700\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0075 - val_loss: 0.0075\n",
      "Epoch 27/700\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0074 - val_loss: 0.0074\n",
      "Epoch 28/700\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0074 - val_loss: 0.0073\n",
      "Epoch 29/700\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0073 - val_loss: 0.0072\n",
      "Epoch 30/700\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0072 - val_loss: 0.0072\n",
      "Epoch 31/700\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0071 - val_loss: 0.0071\n",
      "Epoch 32/700\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0071 - val_loss: 0.0070\n",
      "Epoch 33/700\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0070 - val_loss: 0.0070\n",
      "Epoch 34/700\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0069 - val_loss: 0.0069\n",
      "Epoch 35/700\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0069 - val_loss: 0.0069\n",
      "Epoch 36/700\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0068 - val_loss: 0.0068\n",
      "Epoch 37/700\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0068 - val_loss: 0.0068\n",
      "Epoch 38/700\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0067 - val_loss: 0.0067\n",
      "Epoch 39/700\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0067 - val_loss: 0.0067\n",
      "Epoch 40/700\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0066 - val_loss: 0.0066\n",
      "Epoch 41/700\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0066 - val_loss: 0.0066\n",
      "Epoch 42/700\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0065 - val_loss: 0.0065\n",
      "Epoch 43/700\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0064 - val_loss: 0.0065\n",
      "Epoch 44/700\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0064 - val_loss: 0.0064\n",
      "Epoch 45/700\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0063 - val_loss: 0.0064\n",
      "Epoch 46/700\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0062 - val_loss: 0.0063\n",
      "Epoch 47/700\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0062 - val_loss: 0.0063\n",
      "Epoch 48/700\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0061 - val_loss: 0.0062\n",
      "Epoch 49/700\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0061 - val_loss: 0.0062\n",
      "Epoch 50/700\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0060 - val_loss: 0.0061\n",
      "Epoch 51/700\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0059 - val_loss: 0.0061\n",
      "Epoch 52/700\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0059 - val_loss: 0.0060\n",
      "Epoch 53/700\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0058 - val_loss: 0.0060\n",
      "Epoch 54/700\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0058 - val_loss: 0.0059\n",
      "Epoch 55/700\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0057 - val_loss: 0.0059\n",
      "Epoch 56/700\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0057 - val_loss: 0.0058\n",
      "Epoch 57/700\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0057 - val_loss: 0.0058\n",
      "Epoch 58/700\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0056 - val_loss: 0.0058\n",
      "Epoch 59/700\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0056 - val_loss: 0.0057\n",
      "Epoch 60/700\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0055 - val_loss: 0.0057\n",
      "Epoch 61/700\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0055 - val_loss: 0.0056\n",
      "Epoch 62/700\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0054 - val_loss: 0.0055\n",
      "Epoch 63/700\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0054 - val_loss: 0.0055\n",
      "Epoch 64/700\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0053 - val_loss: 0.0054\n",
      "Epoch 65/700\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0053 - val_loss: 0.0054\n",
      "Epoch 66/700\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0052 - val_loss: 0.0053\n",
      "Epoch 67/700\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0052 - val_loss: 0.0052\n",
      "Epoch 68/700\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0051 - val_loss: 0.0052\n",
      "Epoch 69/700\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0051 - val_loss: 0.0051\n",
      "Epoch 70/700\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0050 - val_loss: 0.0051\n",
      "Epoch 71/700\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0050 - val_loss: 0.0050\n",
      "Epoch 72/700\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0049 - val_loss: 0.0050\n",
      "Epoch 73/700\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0049 - val_loss: 0.0050\n",
      "Epoch 74/700\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 75/700\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0048 - val_loss: 0.0049\n",
      "Epoch 76/700\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0048 - val_loss: 0.0049\n",
      "Epoch 77/700\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0048 - val_loss: 0.0048\n",
      "Epoch 78/700\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0048 - val_loss: 0.0048\n",
      "Epoch 79/700\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0047 - val_loss: 0.0048\n",
      "Epoch 80/700\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0047 - val_loss: 0.0048\n",
      "Epoch 81/700\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0047 - val_loss: 0.0048\n",
      "Epoch 82/700\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0047 - val_loss: 0.0048\n",
      "Epoch 83/700\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0047 - val_loss: 0.0048\n",
      "Epoch 84/700\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0047 - val_loss: 0.0048\n",
      "Epoch 85/700\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0047 - val_loss: 0.0048\n",
      "Epoch 86/700\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0047 - val_loss: 0.0048\n",
      "Epoch 87/700\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0047 - val_loss: 0.0048\n",
      "Epoch 88/700\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0047 - val_loss: 0.0047\n",
      "Epoch 89/700\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0047 - val_loss: 0.0047\n",
      "Epoch 90/700\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0047 - val_loss: 0.0047\n",
      "Epoch 91/700\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0046 - val_loss: 0.0047\n",
      "Epoch 92/700\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0046 - val_loss: 0.0047\n",
      "Epoch 93/700\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0046 - val_loss: 0.0047\n",
      "Epoch 94/700\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0046 - val_loss: 0.0047\n",
      "Epoch 95/700\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0046 - val_loss: 0.0047\n",
      "Epoch 96/700\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0046 - val_loss: 0.0047\n",
      "Epoch 97/700\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0046 - val_loss: 0.0047\n",
      "Epoch 98/700\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0046 - val_loss: 0.0047\n",
      "Epoch 99/700\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0046 - val_loss: 0.0047\n",
      "Epoch 100/700\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0046 - val_loss: 0.0047\n",
      "Epoch 101/700\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0046 - val_loss: 0.0047\n",
      "Epoch 102/700\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0046 - val_loss: 0.0047\n",
      "Epoch 103/700\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0046 - val_loss: 0.0047\n",
      "Epoch 104/700\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0046 - val_loss: 0.0047\n",
      "Epoch 105/700\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0046 - val_loss: 0.0047\n",
      "Epoch 106/700\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0046 - val_loss: 0.0047\n",
      "Epoch 107/700\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0046 - val_loss: 0.0046\n",
      "Epoch 108/700\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0046 - val_loss: 0.0046\n",
      "Epoch 109/700\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0046 - val_loss: 0.0046\n",
      "Epoch 110/700\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0046 - val_loss: 0.0046\n",
      "Epoch 111/700\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0045 - val_loss: 0.0046\n",
      "Epoch 112/700\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0045 - val_loss: 0.0046\n",
      "Epoch 113/700\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0045 - val_loss: 0.0046\n",
      "Epoch 114/700\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0045 - val_loss: 0.0046\n",
      "Epoch 115/700\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0045 - val_loss: 0.0046\n",
      "Epoch 116/700\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0045 - val_loss: 0.0046\n",
      "Epoch 117/700\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0045 - val_loss: 0.0046\n",
      "Epoch 118/700\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0045 - val_loss: 0.0046\n",
      "Epoch 119/700\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0045 - val_loss: 0.0046\n",
      "Epoch 120/700\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0045 - val_loss: 0.0046\n",
      "Epoch 121/700\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0045 - val_loss: 0.0046\n",
      "Epoch 122/700\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0045 - val_loss: 0.0046\n",
      "Epoch 123/700\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0045 - val_loss: 0.0046\n",
      "Epoch 124/700\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0045 - val_loss: 0.0046\n",
      "Epoch 125/700\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0045 - val_loss: 0.0046\n",
      "Epoch 126/700\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0045 - val_loss: 0.0046\n",
      "Epoch 127/700\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0045 - val_loss: 0.0046\n",
      "Epoch 128/700\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0045 - val_loss: 0.0046\n",
      "Epoch 129/700\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0045 - val_loss: 0.0046\n",
      "Epoch 130/700\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0045 - val_loss: 0.0046\n",
      "Epoch 131/700\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0045 - val_loss: 0.0046\n",
      "Epoch 132/700\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0045 - val_loss: 0.0045\n",
      "Epoch 133/700\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0045 - val_loss: 0.0045\n",
      "Epoch 134/700\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0045 - val_loss: 0.0045\n",
      "Epoch 135/700\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0045 - val_loss: 0.0045\n",
      "Epoch 136/700\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0044 - val_loss: 0.0045\n",
      "Epoch 137/700\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0044 - val_loss: 0.0045\n",
      "Epoch 138/700\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0044 - val_loss: 0.0045\n",
      "Epoch 139/700\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0044 - val_loss: 0.0045\n",
      "Epoch 140/700\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0044 - val_loss: 0.0045\n",
      "Epoch 141/700\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0044 - val_loss: 0.0045\n",
      "Epoch 142/700\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0044 - val_loss: 0.0045\n",
      "Epoch 143/700\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0044 - val_loss: 0.0045\n",
      "Epoch 144/700\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0044 - val_loss: 0.0045\n",
      "Epoch 145/700\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0044 - val_loss: 0.0045\n",
      "Epoch 146/700\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0044 - val_loss: 0.0045\n",
      "Epoch 147/700\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0044 - val_loss: 0.0045\n",
      "Epoch 148/700\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0044 - val_loss: 0.0045\n",
      "Epoch 149/700\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0044 - val_loss: 0.0045\n",
      "Epoch 150/700\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0044 - val_loss: 0.0045\n",
      "Epoch 151/700\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0044 - val_loss: 0.0045\n",
      "Epoch 152/700\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0044 - val_loss: 0.0045\n",
      "Epoch 153/700\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0044 - val_loss: 0.0045\n",
      "Epoch 154/700\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0044 - val_loss: 0.0045\n",
      "Epoch 155/700\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0044 - val_loss: 0.0045\n",
      "Epoch 156/700\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0044 - val_loss: 0.0045\n",
      "Epoch 157/700\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0044 - val_loss: 0.0045\n",
      "Epoch 158/700\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0044 - val_loss: 0.0045\n",
      "Epoch 159/700\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0044 - val_loss: 0.0045\n",
      "Epoch 160/700\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0044 - val_loss: 0.0045\n",
      "Epoch 161/700\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0044 - val_loss: 0.0045\n",
      "Epoch 162/700\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0044 - val_loss: 0.0045\n",
      "Epoch 163/700\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0044 - val_loss: 0.0045\n",
      "Epoch 164/700\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0044 - val_loss: 0.0045\n",
      "Epoch 165/700\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0044 - val_loss: 0.0045\n",
      "Epoch 166/700\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0044 - val_loss: 0.0045\n",
      "Epoch 167/700\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0044 - val_loss: 0.0045\n",
      "Epoch 168/700\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0044 - val_loss: 0.0045\n",
      "Epoch 169/700\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0044 - val_loss: 0.0045\n",
      "Epoch 170/700\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0044 - val_loss: 0.0045\n",
      "Epoch 171/700\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0044 - val_loss: 0.0045\n",
      "Epoch 172/700\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0044 - val_loss: 0.0045\n",
      "Epoch 173/700\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0044 - val_loss: 0.0045\n",
      "Epoch 174/700\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0044 - val_loss: 0.0045\n",
      "Epoch 175/700\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0044 - val_loss: 0.0045\n",
      "Epoch 176/700\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0044 - val_loss: 0.0045\n",
      "Epoch 177/700\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0044 - val_loss: 0.0045\n",
      "Epoch 178/700\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0044 - val_loss: 0.0045\n",
      "Epoch 179/700\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0044 - val_loss: 0.0045\n",
      "Epoch 180/700\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0044 - val_loss: 0.0045\n",
      "Epoch 181/700\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0044 - val_loss: 0.0045\n",
      "Epoch 182/700\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0044 - val_loss: 0.0045\n",
      "Epoch 183/700\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0044 - val_loss: 0.0045\n",
      "Epoch 184/700\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0044 - val_loss: 0.0045\n",
      "Epoch 185/700\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0044 - val_loss: 0.0045\n",
      "Epoch 186/700\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0044 - val_loss: 0.0045\n",
      "Epoch 187/700\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0044 - val_loss: 0.0044\n",
      "Epoch 188/700\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0044 - val_loss: 0.0044\n",
      "Epoch 189/700\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0043 - val_loss: 0.0044\n",
      "Epoch 190/700\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0043 - val_loss: 0.0044\n",
      "Epoch 191/700\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0043 - val_loss: 0.0044\n",
      "Epoch 192/700\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0043 - val_loss: 0.0044\n",
      "Epoch 193/700\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0043 - val_loss: 0.0044\n",
      "Epoch 194/700\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0043 - val_loss: 0.0044\n",
      "Epoch 195/700\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0043 - val_loss: 0.0044\n",
      "Epoch 196/700\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0043 - val_loss: 0.0044\n",
      "Epoch 197/700\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 0.0043 - val_loss: 0.0044\n",
      "Epoch 198/700\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0043 - val_loss: 0.0044\n",
      "Epoch 199/700\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0043 - val_loss: 0.0044\n",
      "Epoch 200/700\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0043 - val_loss: 0.0044\n",
      "Epoch 201/700\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0043 - val_loss: 0.0044\n",
      "Epoch 202/700\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0043 - val_loss: 0.0044\n",
      "Epoch 203/700\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0043 - val_loss: 0.0044\n",
      "Epoch 204/700\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0043 - val_loss: 0.0044\n",
      "Epoch 205/700\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0043 - val_loss: 0.0044\n",
      "Epoch 206/700\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0043 - val_loss: 0.0044\n",
      "Epoch 207/700\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0043 - val_loss: 0.0044\n",
      "Epoch 208/700\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0043 - val_loss: 0.0044\n",
      "Epoch 209/700\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0043 - val_loss: 0.0044\n",
      "Epoch 210/700\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0043 - val_loss: 0.0044\n",
      "Epoch 211/700\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0043 - val_loss: 0.0044\n",
      "Epoch 212/700\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0043 - val_loss: 0.0044\n",
      "Epoch 213/700\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0043 - val_loss: 0.0044\n",
      "Epoch 214/700\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0043 - val_loss: 0.0044\n",
      "Epoch 215/700\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0043 - val_loss: 0.0044\n",
      "Epoch 216/700\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0043 - val_loss: 0.0044\n",
      "Epoch 217/700\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0043 - val_loss: 0.0044\n",
      "Epoch 218/700\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0043 - val_loss: 0.0044\n",
      "Epoch 219/700\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0043 - val_loss: 0.0044\n",
      "Epoch 220/700\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0043 - val_loss: 0.0044\n",
      "Epoch 221/700\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0043 - val_loss: 0.0044\n",
      "Epoch 222/700\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0043 - val_loss: 0.0044\n",
      "Epoch 223/700\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0043 - val_loss: 0.0044\n",
      "Epoch 224/700\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0043 - val_loss: 0.0044\n",
      "Epoch 225/700\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0043 - val_loss: 0.0044\n",
      "Epoch 226/700\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0043 - val_loss: 0.0044\n",
      "Epoch 227/700\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0043 - val_loss: 0.0044\n",
      "Epoch 228/700\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0043 - val_loss: 0.0044\n",
      "Epoch 229/700\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0043 - val_loss: 0.0044\n",
      "Epoch 230/700\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0043 - val_loss: 0.0044\n",
      "Epoch 231/700\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0043 - val_loss: 0.0044\n",
      "Epoch 232/700\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0043 - val_loss: 0.0044\n",
      "Epoch 233/700\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0043 - val_loss: 0.0043\n",
      "Epoch 234/700\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0042 - val_loss: 0.0043\n",
      "Epoch 235/700\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0042 - val_loss: 0.0043\n",
      "Epoch 236/700\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0042 - val_loss: 0.0043\n",
      "Epoch 237/700\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0042 - val_loss: 0.0043\n",
      "Epoch 238/700\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0042 - val_loss: 0.0043\n",
      "Epoch 239/700\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0042 - val_loss: 0.0043\n",
      "Epoch 240/700\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0042 - val_loss: 0.0043\n",
      "Epoch 241/700\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0042 - val_loss: 0.0043\n",
      "Epoch 242/700\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0042 - val_loss: 0.0043\n",
      "Epoch 243/700\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0042 - val_loss: 0.0043\n",
      "Epoch 244/700\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0042 - val_loss: 0.0043\n",
      "Epoch 245/700\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0042 - val_loss: 0.0043\n",
      "Epoch 246/700\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0042 - val_loss: 0.0043\n",
      "Epoch 247/700\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0042 - val_loss: 0.0043\n",
      "Epoch 248/700\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.0042 - val_loss: 0.0043\n",
      "Epoch 249/700\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0042 - val_loss: 0.0043\n",
      "Epoch 250/700\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0042 - val_loss: 0.0043\n",
      "Epoch 251/700\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0042 - val_loss: 0.0043\n",
      "Epoch 252/700\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0042 - val_loss: 0.0043\n",
      "Epoch 253/700\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0042 - val_loss: 0.0043\n",
      "Epoch 254/700\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0042 - val_loss: 0.0043\n",
      "Epoch 255/700\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0042 - val_loss: 0.0043\n",
      "Epoch 256/700\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0042 - val_loss: 0.0043\n",
      "Epoch 257/700\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.0042 - val_loss: 0.0043\n",
      "Epoch 258/700\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 0.0042 - val_loss: 0.0043\n",
      "Epoch 259/700\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0042 - val_loss: 0.0043\n",
      "Epoch 260/700\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0042 - val_loss: 0.0043\n",
      "Epoch 261/700\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0042 - val_loss: 0.0043\n",
      "Epoch 262/700\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0042 - val_loss: 0.0043\n",
      "Epoch 263/700\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0041 - val_loss: 0.0043\n",
      "Epoch 264/700\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0041 - val_loss: 0.0043\n",
      "Epoch 265/700\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 0.0041 - val_loss: 0.0042\n",
      "Epoch 266/700\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0041 - val_loss: 0.0042\n",
      "Epoch 267/700\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0041 - val_loss: 0.0042\n",
      "Epoch 268/700\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.0041 - val_loss: 0.0042\n",
      "Epoch 269/700\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0041 - val_loss: 0.0042\n",
      "Epoch 270/700\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0041 - val_loss: 0.0042\n",
      "Epoch 271/700\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0041 - val_loss: 0.0042\n",
      "Epoch 272/700\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0041 - val_loss: 0.0042\n",
      "Epoch 273/700\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0041 - val_loss: 0.0042\n",
      "Epoch 274/700\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0041 - val_loss: 0.0042\n",
      "Epoch 275/700\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0041 - val_loss: 0.0042\n",
      "Epoch 276/700\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0041 - val_loss: 0.0042\n",
      "Epoch 277/700\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0041 - val_loss: 0.0042\n",
      "Epoch 278/700\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0041 - val_loss: 0.0042\n",
      "Epoch 279/700\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0041 - val_loss: 0.0042\n",
      "Epoch 280/700\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0041 - val_loss: 0.0042\n",
      "Epoch 281/700\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0041 - val_loss: 0.0042\n",
      "Epoch 282/700\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0041 - val_loss: 0.0042\n",
      "Epoch 283/700\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0041 - val_loss: 0.0042\n",
      "Epoch 284/700\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0041 - val_loss: 0.0042\n",
      "Epoch 285/700\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0041 - val_loss: 0.0042\n",
      "Epoch 286/700\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0041 - val_loss: 0.0042\n",
      "Epoch 287/700\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0041 - val_loss: 0.0042\n",
      "Epoch 288/700\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0040 - val_loss: 0.0042\n",
      "Epoch 289/700\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0040 - val_loss: 0.0042\n",
      "Epoch 290/700\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0040 - val_loss: 0.0042\n",
      "Epoch 291/700\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0040 - val_loss: 0.0041\n",
      "Epoch 292/700\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0040 - val_loss: 0.0041\n",
      "Epoch 293/700\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0040 - val_loss: 0.0041\n",
      "Epoch 294/700\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0040 - val_loss: 0.0041\n",
      "Epoch 295/700\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0040 - val_loss: 0.0041\n",
      "Epoch 296/700\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0040 - val_loss: 0.0041\n",
      "Epoch 297/700\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0040 - val_loss: 0.0041\n",
      "Epoch 298/700\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0040 - val_loss: 0.0041\n",
      "Epoch 299/700\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0040 - val_loss: 0.0041\n",
      "Epoch 300/700\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0040 - val_loss: 0.0041\n",
      "Epoch 301/700\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0040 - val_loss: 0.0041\n",
      "Epoch 302/700\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0040 - val_loss: 0.0041\n",
      "Epoch 303/700\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0040 - val_loss: 0.0041\n",
      "Epoch 304/700\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0040 - val_loss: 0.0041\n",
      "Epoch 305/700\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0040 - val_loss: 0.0041\n",
      "Epoch 306/700\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0040 - val_loss: 0.0041\n",
      "Epoch 307/700\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0040 - val_loss: 0.0041\n",
      "Epoch 308/700\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0040 - val_loss: 0.0041\n",
      "Epoch 309/700\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0040 - val_loss: 0.0041\n",
      "Epoch 310/700\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0039 - val_loss: 0.0041\n",
      "Epoch 311/700\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0039 - val_loss: 0.0041\n",
      "Epoch 312/700\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0039 - val_loss: 0.0041\n",
      "Epoch 313/700\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0039 - val_loss: 0.0040\n",
      "Epoch 314/700\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0039 - val_loss: 0.0041\n",
      "Epoch 315/700\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0039 - val_loss: 0.0040\n",
      "Epoch 316/700\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0039 - val_loss: 0.0040\n",
      "Epoch 317/700\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0039 - val_loss: 0.0040\n",
      "Epoch 318/700\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0039 - val_loss: 0.0040\n",
      "Epoch 319/700\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0039 - val_loss: 0.0040\n",
      "Epoch 320/700\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0039 - val_loss: 0.0040\n",
      "Epoch 321/700\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0039 - val_loss: 0.0040\n",
      "Epoch 322/700\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0039 - val_loss: 0.0040\n",
      "Epoch 323/700\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0039 - val_loss: 0.0040\n",
      "Epoch 324/700\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0039 - val_loss: 0.0040\n",
      "Epoch 325/700\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0039 - val_loss: 0.0040\n",
      "Epoch 326/700\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0039 - val_loss: 0.0040\n",
      "Epoch 327/700\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0039 - val_loss: 0.0040\n",
      "Epoch 328/700\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0039 - val_loss: 0.0040\n",
      "Epoch 329/700\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0039 - val_loss: 0.0040\n",
      "Epoch 330/700\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0039 - val_loss: 0.0040\n",
      "Epoch 331/700\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0039 - val_loss: 0.0040\n",
      "Epoch 332/700\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0039 - val_loss: 0.0040\n",
      "Epoch 333/700\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0039 - val_loss: 0.0040\n",
      "Epoch 334/700\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0039 - val_loss: 0.0040\n",
      "Epoch 335/700\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0039 - val_loss: 0.0040\n",
      "Epoch 336/700\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0039 - val_loss: 0.0040\n",
      "Epoch 337/700\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0039 - val_loss: 0.0040\n",
      "Epoch 338/700\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0039 - val_loss: 0.0040\n",
      "Epoch 339/700\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0038 - val_loss: 0.0040\n",
      "Epoch 340/700\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0038 - val_loss: 0.0040\n",
      "Epoch 341/700\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0038 - val_loss: 0.0040\n",
      "Epoch 342/700\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0038 - val_loss: 0.0040\n",
      "Epoch 343/700\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0038 - val_loss: 0.0040\n",
      "Epoch 344/700\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0038 - val_loss: 0.0040\n",
      "Epoch 345/700\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 346/700\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0038 - val_loss: 0.0040\n",
      "Epoch 347/700\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 348/700\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 349/700\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 350/700\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 351/700\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 352/700\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 353/700\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 354/700\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 355/700\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 356/700\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 357/700\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 358/700\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 359/700\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 360/700\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 361/700\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 362/700\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 363/700\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 364/700\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 365/700\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 366/700\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 367/700\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 368/700\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 369/700\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 370/700\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 371/700\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 372/700\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 373/700\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 374/700\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 375/700\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 376/700\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 377/700\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 378/700\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0037 - val_loss: 0.0039\n",
      "Epoch 379/700\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0037 - val_loss: 0.0039\n",
      "Epoch 380/700\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0037 - val_loss: 0.0039\n",
      "Epoch 381/700\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0037 - val_loss: 0.0039\n",
      "Epoch 382/700\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0037 - val_loss: 0.0039\n",
      "Epoch 383/700\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 384/700\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0037 - val_loss: 0.0039\n",
      "Epoch 385/700\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 386/700\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0037 - val_loss: 0.0039\n",
      "Epoch 387/700\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 388/700\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 389/700\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 390/700\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 391/700\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 392/700\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 393/700\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 394/700\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 395/700\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 396/700\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 397/700\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 398/700\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 399/700\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 400/700\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 401/700\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 402/700\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 403/700\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 404/700\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 405/700\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 406/700\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 407/700\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 408/700\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 409/700\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 410/700\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 411/700\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 412/700\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 413/700\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 414/700\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 415/700\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 416/700\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 417/700\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 418/700\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0036 - val_loss: 0.0038\n",
      "Epoch 419/700\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0036 - val_loss: 0.0038\n",
      "Epoch 420/700\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0036 - val_loss: 0.0038\n",
      "Epoch 421/700\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0036 - val_loss: 0.0038\n",
      "Epoch 422/700\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0036 - val_loss: 0.0038\n",
      "Epoch 423/700\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0036 - val_loss: 0.0038\n",
      "Epoch 424/700\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0036 - val_loss: 0.0038\n",
      "Epoch 425/700\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0036 - val_loss: 0.0038\n",
      "Epoch 426/700\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0036 - val_loss: 0.0038\n",
      "Epoch 427/700\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0036 - val_loss: 0.0037\n",
      "Epoch 428/700\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0036 - val_loss: 0.0038\n",
      "Epoch 429/700\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0036 - val_loss: 0.0037\n",
      "Epoch 430/700\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0036 - val_loss: 0.0038\n",
      "Epoch 431/700\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0036 - val_loss: 0.0037\n",
      "Epoch 432/700\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0036 - val_loss: 0.0038\n",
      "Epoch 433/700\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0036 - val_loss: 0.0037\n",
      "Epoch 434/700\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0036 - val_loss: 0.0038\n",
      "Epoch 435/700\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0036 - val_loss: 0.0037\n",
      "Epoch 436/700\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0036 - val_loss: 0.0038\n",
      "Epoch 437/700\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0036 - val_loss: 0.0037\n",
      "Epoch 438/700\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0036 - val_loss: 0.0038\n",
      "Epoch 439/700\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 0.0036 - val_loss: 0.0037\n",
      "Epoch 440/700\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.0036 - val_loss: 0.0037\n",
      "Epoch 441/700\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0036 - val_loss: 0.0037\n",
      "Epoch 442/700\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0036 - val_loss: 0.0037\n",
      "Epoch 443/700\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0036 - val_loss: 0.0037\n",
      "Epoch 444/700\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0036 - val_loss: 0.0037\n",
      "Epoch 445/700\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0036 - val_loss: 0.0037\n",
      "Epoch 446/700\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0036 - val_loss: 0.0037\n",
      "Epoch 447/700\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0036 - val_loss: 0.0037\n",
      "Epoch 448/700\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0036 - val_loss: 0.0037\n",
      "Epoch 449/700\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0036 - val_loss: 0.0037\n",
      "Epoch 450/700\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0036 - val_loss: 0.0037\n",
      "Epoch 451/700\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0036 - val_loss: 0.0037\n",
      "Epoch 452/700\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.0036 - val_loss: 0.0037\n",
      "Epoch 453/700\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0036 - val_loss: 0.0037\n",
      "Epoch 454/700\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0036 - val_loss: 0.0037\n",
      "Epoch 455/700\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0036 - val_loss: 0.0037\n",
      "Epoch 456/700\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0036 - val_loss: 0.0037\n",
      "Epoch 457/700\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0036 - val_loss: 0.0037\n",
      "Epoch 458/700\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0036 - val_loss: 0.0037\n",
      "Epoch 459/700\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.0036 - val_loss: 0.0037\n",
      "Epoch 460/700\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0036 - val_loss: 0.0037\n",
      "Epoch 461/700\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.0036 - val_loss: 0.0037\n",
      "Epoch 462/700\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0036 - val_loss: 0.0037\n",
      "Epoch 463/700\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0036 - val_loss: 0.0037\n",
      "Epoch 464/700\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0036 - val_loss: 0.0037\n",
      "Epoch 465/700\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0036 - val_loss: 0.0037\n",
      "Epoch 466/700\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0036 - val_loss: 0.0037\n",
      "Epoch 467/700\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0036 - val_loss: 0.0037\n",
      "Epoch 468/700\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.0036 - val_loss: 0.0037\n",
      "Epoch 469/700\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0036 - val_loss: 0.0037\n",
      "Epoch 470/700\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0036 - val_loss: 0.0037\n",
      "Epoch 471/700\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0036 - val_loss: 0.0037\n",
      "Epoch 472/700\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0036 - val_loss: 0.0037\n",
      "Epoch 473/700\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0036 - val_loss: 0.0037\n",
      "Epoch 474/700\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 0.0036 - val_loss: 0.0037\n",
      "Epoch 475/700\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0036 - val_loss: 0.0037\n",
      "Epoch 476/700\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0036 - val_loss: 0.0037\n",
      "Epoch 477/700\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0036 - val_loss: 0.0037\n",
      "Epoch 478/700\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0035 - val_loss: 0.0037\n",
      "Epoch 479/700\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0036 - val_loss: 0.0037\n",
      "Epoch 480/700\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0035 - val_loss: 0.0037\n",
      "Epoch 481/700\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0035 - val_loss: 0.0037\n",
      "Epoch 482/700\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0035 - val_loss: 0.0037\n",
      "Epoch 483/700\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0035 - val_loss: 0.0037\n",
      "Epoch 484/700\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0035 - val_loss: 0.0037\n",
      "Epoch 485/700\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0035 - val_loss: 0.0037\n",
      "Epoch 486/700\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0035 - val_loss: 0.0037\n",
      "Epoch 487/700\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0035 - val_loss: 0.0037\n",
      "Epoch 488/700\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0035 - val_loss: 0.0037\n",
      "Epoch 489/700\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0035 - val_loss: 0.0037\n",
      "Epoch 490/700\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0035 - val_loss: 0.0037\n",
      "Epoch 491/700\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0035 - val_loss: 0.0037\n",
      "Epoch 492/700\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0035 - val_loss: 0.0037\n",
      "Epoch 493/700\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.0035 - val_loss: 0.0037\n",
      "Epoch 494/700\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0035 - val_loss: 0.0037\n",
      "Epoch 495/700\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0035 - val_loss: 0.0037\n",
      "Epoch 496/700\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0035 - val_loss: 0.0037\n",
      "Epoch 497/700\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0035 - val_loss: 0.0036\n",
      "Epoch 498/700\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0035 - val_loss: 0.0037\n",
      "Epoch 499/700\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0035 - val_loss: 0.0036\n",
      "Epoch 500/700\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0035 - val_loss: 0.0037\n",
      "Epoch 501/700\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0035 - val_loss: 0.0036\n",
      "Epoch 502/700\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0035 - val_loss: 0.0037\n",
      "Epoch 503/700\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.0035 - val_loss: 0.0036\n",
      "Epoch 504/700\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0035 - val_loss: 0.0037\n",
      "Epoch 505/700\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0035 - val_loss: 0.0036\n",
      "Epoch 506/700\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0035 - val_loss: 0.0037\n",
      "Epoch 507/700\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0035 - val_loss: 0.0036\n",
      "Epoch 508/700\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0035 - val_loss: 0.0037\n",
      "Epoch 509/700\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0035 - val_loss: 0.0036\n",
      "Epoch 510/700\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0035 - val_loss: 0.0037\n",
      "Epoch 511/700\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0035 - val_loss: 0.0036\n",
      "Epoch 512/700\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0035 - val_loss: 0.0036\n",
      "Epoch 513/700\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0035 - val_loss: 0.0036\n",
      "Epoch 514/700\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0035 - val_loss: 0.0036\n",
      "Epoch 515/700\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0035 - val_loss: 0.0036\n",
      "Epoch 516/700\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0035 - val_loss: 0.0036\n",
      "Epoch 517/700\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0035 - val_loss: 0.0036\n",
      "Epoch 518/700\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0035 - val_loss: 0.0036\n",
      "Epoch 519/700\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.0035 - val_loss: 0.0036\n",
      "Epoch 520/700\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.0035 - val_loss: 0.0036\n",
      "Epoch 521/700\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0035 - val_loss: 0.0036\n",
      "Epoch 522/700\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0035 - val_loss: 0.0036\n",
      "Epoch 523/700\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0035 - val_loss: 0.0036\n",
      "Epoch 524/700\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0035 - val_loss: 0.0036\n",
      "Epoch 525/700\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0035 - val_loss: 0.0036\n",
      "Epoch 526/700\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0035 - val_loss: 0.0036\n",
      "Epoch 527/700\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0035 - val_loss: 0.0036\n",
      "Epoch 528/700\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 0.0035 - val_loss: 0.0036\n",
      "Epoch 529/700\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0035 - val_loss: 0.0036\n",
      "Epoch 530/700\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0035 - val_loss: 0.0036\n",
      "Epoch 531/700\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0035 - val_loss: 0.0036\n",
      "Epoch 532/700\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0035 - val_loss: 0.0036\n",
      "Epoch 533/700\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0035 - val_loss: 0.0036\n",
      "Epoch 534/700\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0035 - val_loss: 0.0036\n",
      "Epoch 535/700\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0035 - val_loss: 0.0036\n",
      "Epoch 536/700\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.0035 - val_loss: 0.0036\n",
      "Epoch 537/700\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.0035 - val_loss: 0.0036\n",
      "Epoch 538/700\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.0035 - val_loss: 0.0036\n",
      "Epoch 539/700\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0035 - val_loss: 0.0036\n",
      "Epoch 540/700\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0035 - val_loss: 0.0036\n",
      "Epoch 541/700\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0035 - val_loss: 0.0036\n",
      "Epoch 542/700\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 0.0035 - val_loss: 0.0036\n",
      "Epoch 543/700\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.0035 - val_loss: 0.0036\n",
      "Epoch 544/700\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0035 - val_loss: 0.0036\n",
      "Epoch 545/700\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0035 - val_loss: 0.0036\n",
      "Epoch 546/700\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0035 - val_loss: 0.0036\n",
      "Epoch 547/700\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0035 - val_loss: 0.0036\n",
      "Epoch 548/700\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0035 - val_loss: 0.0036\n",
      "Epoch 549/700\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0035 - val_loss: 0.0036\n",
      "Epoch 550/700\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0034 - val_loss: 0.0036\n",
      "Epoch 551/700\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.0034 - val_loss: 0.0036\n",
      "Epoch 552/700\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0034 - val_loss: 0.0036\n",
      "Epoch 553/700\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0034 - val_loss: 0.0036\n",
      "Epoch 554/700\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0034 - val_loss: 0.0036\n",
      "Epoch 555/700\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0034 - val_loss: 0.0036\n",
      "Epoch 556/700\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0034 - val_loss: 0.0036\n",
      "Epoch 557/700\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0034 - val_loss: 0.0036\n",
      "Epoch 558/700\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0034 - val_loss: 0.0036\n",
      "Epoch 559/700\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0034 - val_loss: 0.0036\n",
      "Epoch 560/700\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0034 - val_loss: 0.0036\n",
      "Epoch 561/700\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.0034 - val_loss: 0.0036\n",
      "Epoch 562/700\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.0034 - val_loss: 0.0036\n",
      "Epoch 563/700\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0034 - val_loss: 0.0035\n",
      "Epoch 564/700\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0034 - val_loss: 0.0036\n",
      "Epoch 565/700\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0034 - val_loss: 0.0035\n",
      "Epoch 566/700\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0034 - val_loss: 0.0036\n",
      "Epoch 567/700\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0034 - val_loss: 0.0035\n",
      "Epoch 568/700\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0034 - val_loss: 0.0036\n",
      "Epoch 569/700\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.0034 - val_loss: 0.0035\n",
      "Epoch 570/700\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 0.0034 - val_loss: 0.0036\n",
      "Epoch 571/700\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0034 - val_loss: 0.0035\n",
      "Epoch 572/700\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0034 - val_loss: 0.0036\n",
      "Epoch 573/700\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0034 - val_loss: 0.0035\n",
      "Epoch 574/700\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0034 - val_loss: 0.0036\n",
      "Epoch 575/700\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0034 - val_loss: 0.0035\n",
      "Epoch 576/700\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0034 - val_loss: 0.0036\n",
      "Epoch 577/700\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0034 - val_loss: 0.0035\n",
      "Epoch 578/700\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0034 - val_loss: 0.0036\n",
      "Epoch 579/700\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0034 - val_loss: 0.0035\n",
      "Epoch 580/700\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0034 - val_loss: 0.0036\n",
      "Epoch 581/700\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0034 - val_loss: 0.0035\n",
      "Epoch 582/700\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0034 - val_loss: 0.0035\n",
      "Epoch 583/700\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0034 - val_loss: 0.0035\n",
      "Epoch 584/700\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0034 - val_loss: 0.0035\n",
      "Epoch 585/700\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.0034 - val_loss: 0.0035\n",
      "Epoch 586/700\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 0.0034 - val_loss: 0.0035\n",
      "Epoch 587/700\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0034 - val_loss: 0.0035\n",
      "Epoch 588/700\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0034 - val_loss: 0.0035\n",
      "Epoch 589/700\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0034 - val_loss: 0.0035\n",
      "Epoch 590/700\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0034 - val_loss: 0.0035\n",
      "Epoch 591/700\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0034 - val_loss: 0.0035\n",
      "Epoch 592/700\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0034 - val_loss: 0.0035\n",
      "Epoch 593/700\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0034 - val_loss: 0.0035\n",
      "Epoch 594/700\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.0034 - val_loss: 0.0035\n",
      "Epoch 595/700\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0034 - val_loss: 0.0035\n",
      "Epoch 596/700\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0034 - val_loss: 0.0035\n",
      "Epoch 597/700\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0034 - val_loss: 0.0035\n",
      "Epoch 598/700\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0034 - val_loss: 0.0035\n",
      "Epoch 599/700\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0034 - val_loss: 0.0035\n",
      "Epoch 600/700\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0034 - val_loss: 0.0035\n",
      "Epoch 601/700\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0034 - val_loss: 0.0035\n",
      "Epoch 602/700\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.0034 - val_loss: 0.0035\n",
      "Epoch 603/700\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0034 - val_loss: 0.0035\n",
      "Epoch 604/700\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0034 - val_loss: 0.0035\n",
      "Epoch 605/700\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0034 - val_loss: 0.0035\n",
      "Epoch 606/700\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0034 - val_loss: 0.0035\n",
      "Epoch 607/700\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0034 - val_loss: 0.0035\n",
      "Epoch 608/700\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0034 - val_loss: 0.0035\n",
      "Epoch 609/700\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0034 - val_loss: 0.0035\n",
      "Epoch 610/700\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0034 - val_loss: 0.0035\n",
      "Epoch 611/700\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0034 - val_loss: 0.0035\n",
      "Epoch 612/700\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0034 - val_loss: 0.0035\n",
      "Epoch 613/700\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 0.0034 - val_loss: 0.0035\n",
      "Epoch 614/700\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0034 - val_loss: 0.0035\n",
      "Epoch 615/700\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0034 - val_loss: 0.0035\n",
      "Epoch 616/700\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0034 - val_loss: 0.0035\n",
      "Epoch 617/700\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0034 - val_loss: 0.0035\n",
      "Epoch 618/700\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0034 - val_loss: 0.0035\n",
      "Epoch 619/700\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0034 - val_loss: 0.0035\n",
      "Epoch 620/700\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 0.0034 - val_loss: 0.0035\n",
      "Epoch 621/700\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0034 - val_loss: 0.0035\n",
      "Epoch 622/700\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.0034 - val_loss: 0.0035\n",
      "Epoch 623/700\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0034 - val_loss: 0.0035\n",
      "Epoch 624/700\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0034 - val_loss: 0.0035\n",
      "Epoch 625/700\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0034 - val_loss: 0.0035\n",
      "Epoch 626/700\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0034 - val_loss: 0.0035\n",
      "Epoch 627/700\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0034 - val_loss: 0.0035\n",
      "Epoch 628/700\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0034 - val_loss: 0.0035\n",
      "Epoch 629/700\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0034 - val_loss: 0.0035\n",
      "Epoch 630/700\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0034 - val_loss: 0.0035\n",
      "Epoch 631/700\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0034 - val_loss: 0.0035\n",
      "Epoch 632/700\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0033 - val_loss: 0.0035\n",
      "Epoch 633/700\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0034 - val_loss: 0.0035\n",
      "Epoch 634/700\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0033 - val_loss: 0.0035\n",
      "Epoch 635/700\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0034 - val_loss: 0.0035\n",
      "Epoch 636/700\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0033 - val_loss: 0.0035\n",
      "Epoch 637/700\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0034 - val_loss: 0.0035\n",
      "Epoch 638/700\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0033 - val_loss: 0.0035\n",
      "Epoch 639/700\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0033 - val_loss: 0.0035\n",
      "Epoch 640/700\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0033 - val_loss: 0.0035\n",
      "Epoch 641/700\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0033 - val_loss: 0.0035\n",
      "Epoch 642/700\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0033 - val_loss: 0.0035\n",
      "Epoch 643/700\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0033 - val_loss: 0.0034\n",
      "Epoch 644/700\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0033 - val_loss: 0.0035\n",
      "Epoch 645/700\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0033 - val_loss: 0.0034\n",
      "Epoch 646/700\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.0033 - val_loss: 0.0035\n",
      "Epoch 647/700\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0033 - val_loss: 0.0034\n",
      "Epoch 648/700\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0033 - val_loss: 0.0035\n",
      "Epoch 649/700\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0033 - val_loss: 0.0034\n",
      "Epoch 650/700\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0033 - val_loss: 0.0035\n",
      "Epoch 651/700\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0033 - val_loss: 0.0034\n",
      "Epoch 652/700\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0033 - val_loss: 0.0035\n",
      "Epoch 653/700\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0033 - val_loss: 0.0034\n",
      "Epoch 654/700\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0033 - val_loss: 0.0035\n",
      "Epoch 655/700\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0033 - val_loss: 0.0034\n",
      "Epoch 656/700\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0033 - val_loss: 0.0035\n",
      "Epoch 657/700\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0033 - val_loss: 0.0034\n",
      "Epoch 658/700\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0033 - val_loss: 0.0035\n",
      "Epoch 659/700\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0033 - val_loss: 0.0034\n",
      "Epoch 660/700\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0033 - val_loss: 0.0035\n",
      "Epoch 661/700\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0033 - val_loss: 0.0034\n",
      "Epoch 662/700\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0033 - val_loss: 0.0035\n",
      "Epoch 663/700\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0033 - val_loss: 0.0034\n",
      "Epoch 664/700\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0033 - val_loss: 0.0035\n",
      "Epoch 665/700\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0033 - val_loss: 0.0034\n",
      "Epoch 666/700\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0033 - val_loss: 0.0034\n",
      "Epoch 667/700\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0033 - val_loss: 0.0034\n",
      "Epoch 668/700\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0033 - val_loss: 0.0034\n",
      "Epoch 669/700\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0033 - val_loss: 0.0034\n",
      "Epoch 670/700\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0033 - val_loss: 0.0034\n",
      "Epoch 671/700\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0033 - val_loss: 0.0034\n",
      "Epoch 672/700\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0033 - val_loss: 0.0034\n",
      "Epoch 673/700\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0033 - val_loss: 0.0034\n",
      "Epoch 674/700\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.0033 - val_loss: 0.0034\n",
      "Epoch 675/700\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0033 - val_loss: 0.0034\n",
      "Epoch 676/700\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0033 - val_loss: 0.0034\n",
      "Epoch 677/700\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0033 - val_loss: 0.0034\n",
      "Epoch 678/700\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0033 - val_loss: 0.0034\n",
      "Epoch 679/700\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0033 - val_loss: 0.0034\n",
      "Epoch 680/700\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0033 - val_loss: 0.0034\n",
      "Epoch 681/700\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0033 - val_loss: 0.0034\n",
      "Epoch 682/700\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0033 - val_loss: 0.0034\n",
      "Epoch 683/700\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0033 - val_loss: 0.0034\n",
      "Epoch 684/700\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0033 - val_loss: 0.0034\n",
      "Epoch 685/700\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0033 - val_loss: 0.0034\n",
      "Epoch 686/700\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0033 - val_loss: 0.0034\n",
      "Epoch 687/700\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0033 - val_loss: 0.0034\n",
      "Epoch 688/700\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0033 - val_loss: 0.0034\n",
      "Epoch 689/700\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0033 - val_loss: 0.0034\n",
      "Epoch 690/700\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0033 - val_loss: 0.0034\n",
      "Epoch 691/700\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0033 - val_loss: 0.0034\n",
      "Epoch 692/700\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0033 - val_loss: 0.0034\n",
      "Epoch 693/700\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0033 - val_loss: 0.0034\n",
      "Epoch 694/700\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0033 - val_loss: 0.0034\n",
      "Epoch 695/700\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0033 - val_loss: 0.0034\n",
      "Epoch 696/700\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0033 - val_loss: 0.0034\n",
      "Epoch 697/700\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0033 - val_loss: 0.0034\n",
      "Epoch 698/700\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0033 - val_loss: 0.0034\n",
      "Epoch 699/700\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0033 - val_loss: 0.0034\n",
      "Epoch 700/700\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0033 - val_loss: 0.0034\n"
     ]
    }
   ],
   "source": [
    "history2 = model2.fit(\n",
    "    x=X_train,\n",
    "    y=y_train,\n",
    "    batch_size=X_train.shape[0],\n",
    "    epochs=700,\n",
    "    validation_data=(X_val, y_val),\n",
    "    shuffle=False,\n",
    "    steps_per_epoch=1,\n",
    "    validation_steps=1,\n",
    "    validation_batch_size=X_val.shape[0]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/700\n",
      "1/1 [==============================] - 1s 926ms/step - loss: 0.0039 - val_loss: 0.0077\n",
      "Epoch 2/700\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0078 - val_loss: 0.0040\n",
      "Epoch 3/700\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0039 - val_loss: 0.0040\n",
      "Epoch 4/700\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0039 - val_loss: 0.0040\n",
      "Epoch 5/700\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0039 - val_loss: 0.0040\n",
      "Epoch 6/700\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0039 - val_loss: 0.0040\n",
      "Epoch 7/700\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0039 - val_loss: 0.0040\n",
      "Epoch 8/700\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0039 - val_loss: 0.0040\n",
      "Epoch 9/700\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0040 - val_loss: 0.0040\n",
      "Epoch 10/700\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0039 - val_loss: 0.0040\n",
      "Epoch 11/700\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0039 - val_loss: 0.0040\n",
      "Epoch 12/700\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0039 - val_loss: 0.0040\n",
      "Epoch 13/700\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0039 - val_loss: 0.0040\n",
      "Epoch 14/700\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0039 - val_loss: 0.0040\n",
      "Epoch 15/700\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0039 - val_loss: 0.0040\n",
      "Epoch 16/700\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 17/700\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 18/700\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 19/700\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 20/700\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 21/700\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 22/700\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 23/700\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 24/700\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 25/700\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 26/700\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 27/700\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 28/700\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 29/700\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 30/700\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 31/700\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 32/700\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 33/700\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 34/700\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 35/700\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 36/700\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 37/700\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 38/700\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 39/700\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 40/700\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 41/700\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 42/700\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 43/700\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 44/700\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 45/700\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 46/700\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 47/700\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 48/700\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 49/700\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 50/700\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 51/700\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 52/700\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 53/700\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 54/700\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 55/700\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 56/700\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 57/700\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 58/700\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 59/700\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 60/700\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 61/700\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 62/700\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 63/700\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 64/700\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 65/700\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 66/700\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 67/700\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 68/700\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 69/700\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 70/700\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 71/700\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 72/700\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 73/700\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 74/700\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 75/700\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 76/700\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 77/700\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 78/700\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 79/700\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 80/700\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 81/700\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 82/700\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 83/700\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 84/700\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 85/700\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 86/700\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 87/700\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 88/700\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 89/700\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 90/700\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 91/700\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 92/700\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 93/700\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 94/700\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 95/700\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 96/700\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 97/700\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 98/700\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 99/700\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 100/700\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 101/700\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 102/700\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 103/700\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 104/700\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 105/700\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 106/700\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 107/700\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 108/700\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 109/700\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 110/700\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 111/700\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 112/700\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 113/700\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 114/700\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 115/700\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 116/700\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 117/700\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 118/700\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 119/700\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 120/700\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 121/700\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 122/700\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 123/700\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 124/700\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 125/700\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 126/700\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 127/700\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 128/700\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 129/700\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 130/700\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 131/700\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 132/700\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 133/700\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 134/700\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 135/700\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 136/700\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 137/700\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 138/700\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 139/700\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 140/700\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 141/700\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 142/700\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 143/700\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 144/700\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 145/700\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 146/700\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 147/700\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 148/700\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 149/700\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 150/700\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 151/700\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 152/700\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 153/700\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 154/700\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 155/700\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 156/700\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 157/700\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 158/700\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 159/700\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 160/700\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 161/700\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0039 - val_loss: 0.0040\n",
      "Epoch 162/700\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 163/700\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0039 - val_loss: 0.0040\n",
      "Epoch 164/700\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 165/700\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0039 - val_loss: 0.0040\n",
      "Epoch 166/700\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0039 - val_loss: 0.0040\n",
      "Epoch 167/700\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0039 - val_loss: 0.0040\n",
      "Epoch 168/700\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0039 - val_loss: 0.0040\n",
      "Epoch 169/700\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0039 - val_loss: 0.0040\n",
      "Epoch 170/700\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 171/700\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0039 - val_loss: 0.0040\n",
      "Epoch 172/700\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 173/700\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0039 - val_loss: 0.0040\n",
      "Epoch 174/700\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 175/700\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0039 - val_loss: 0.0040\n",
      "Epoch 176/700\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 177/700\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 178/700\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 179/700\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 180/700\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 181/700\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 182/700\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 183/700\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 184/700\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 185/700\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 186/700\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 187/700\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 188/700\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 189/700\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 190/700\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 191/700\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 192/700\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 193/700\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 194/700\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 195/700\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 196/700\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 197/700\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 198/700\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 199/700\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 200/700\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 201/700\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 202/700\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 203/700\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 204/700\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 205/700\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 206/700\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 207/700\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 208/700\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 209/700\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 210/700\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 211/700\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 212/700\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 213/700\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 214/700\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 215/700\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 216/700\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 217/700\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 218/700\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 219/700\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 220/700\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 221/700\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 222/700\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 223/700\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 224/700\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 225/700\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0039 - val_loss: 0.0040\n",
      "Epoch 226/700\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 227/700\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0039 - val_loss: 0.0040\n",
      "Epoch 228/700\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 229/700\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0039 - val_loss: 0.0040\n",
      "Epoch 230/700\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0039 - val_loss: 0.0040\n",
      "Epoch 231/700\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0039 - val_loss: 0.0040\n",
      "Epoch 232/700\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0039 - val_loss: 0.0040\n",
      "Epoch 233/700\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0039 - val_loss: 0.0040\n",
      "Epoch 234/700\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0039 - val_loss: 0.0040\n",
      "Epoch 235/700\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0039 - val_loss: 0.0040\n",
      "Epoch 236/700\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 237/700\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 238/700\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 239/700\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 240/700\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 241/700\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 242/700\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 243/700\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 244/700\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 245/700\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 246/700\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 247/700\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 248/700\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 249/700\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 250/700\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 251/700\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 252/700\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 253/700\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 254/700\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 255/700\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 256/700\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 257/700\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 258/700\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 259/700\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 260/700\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 261/700\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 262/700\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 263/700\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 264/700\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 265/700\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 266/700\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 267/700\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 268/700\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 269/700\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 270/700\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 271/700\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 272/700\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.0039 - val_loss: 0.0040\n",
      "Epoch 273/700\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 274/700\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0039 - val_loss: 0.0040\n",
      "Epoch 275/700\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 276/700\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0039 - val_loss: 0.0040\n",
      "Epoch 277/700\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0039 - val_loss: 0.0040\n",
      "Epoch 278/700\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0039 - val_loss: 0.0040\n",
      "Epoch 279/700\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 280/700\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0039 - val_loss: 0.0040\n",
      "Epoch 281/700\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 282/700\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0039 - val_loss: 0.0040\n",
      "Epoch 283/700\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 284/700\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0039 - val_loss: 0.0040\n",
      "Epoch 285/700\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 286/700\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0039 - val_loss: 0.0040\n",
      "Epoch 287/700\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 288/700\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 289/700\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 290/700\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 291/700\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 292/700\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 293/700\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 294/700\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 295/700\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 296/700\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 297/700\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 298/700\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 299/700\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 300/700\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 301/700\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 302/700\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 303/700\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 304/700\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 305/700\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 306/700\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 307/700\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 308/700\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 309/700\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 310/700\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 311/700\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 312/700\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 313/700\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 314/700\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 315/700\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 316/700\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 317/700\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 318/700\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 319/700\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 320/700\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 321/700\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 322/700\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 323/700\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 324/700\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 325/700\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 326/700\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 327/700\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 328/700\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 329/700\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 330/700\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 331/700\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 332/700\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 333/700\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 334/700\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 335/700\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 336/700\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 337/700\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 338/700\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 339/700\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 340/700\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 341/700\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 342/700\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 343/700\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 344/700\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 345/700\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 346/700\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 347/700\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 348/700\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 349/700\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 350/700\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 351/700\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 352/700\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 353/700\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 354/700\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0039 - val_loss: 0.0040\n",
      "Epoch 355/700\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 356/700\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0039 - val_loss: 0.0040\n",
      "Epoch 357/700\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 358/700\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.0039 - val_loss: 0.0040\n",
      "Epoch 359/700\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 360/700\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0039 - val_loss: 0.0040\n",
      "Epoch 361/700\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 362/700\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 363/700\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 364/700\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 365/700\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 366/700\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 367/700\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 368/700\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 369/700\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 370/700\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 371/700\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 372/700\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 373/700\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 374/700\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 375/700\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 376/700\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 377/700\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 378/700\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 379/700\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 380/700\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 381/700\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 382/700\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 383/700\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 384/700\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 385/700\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 386/700\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 387/700\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 388/700\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 389/700\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 390/700\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 391/700\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 392/700\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 393/700\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 394/700\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 395/700\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 396/700\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 397/700\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 398/700\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 399/700\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 400/700\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 401/700\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 402/700\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 403/700\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 404/700\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 405/700\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 406/700\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 407/700\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 408/700\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 409/700\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 410/700\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 411/700\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 412/700\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 413/700\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 414/700\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 415/700\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 416/700\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 417/700\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 418/700\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 419/700\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 420/700\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 421/700\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 422/700\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 423/700\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 424/700\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 425/700\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 426/700\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 427/700\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 428/700\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0039 - val_loss: 0.0040\n",
      "Epoch 429/700\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 430/700\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0039 - val_loss: 0.0040\n",
      "Epoch 431/700\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 432/700\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0039 - val_loss: 0.0040\n",
      "Epoch 433/700\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0039 - val_loss: 0.0040\n",
      "Epoch 434/700\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0039 - val_loss: 0.0040\n",
      "Epoch 435/700\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0039 - val_loss: 0.0040\n",
      "Epoch 436/700\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0039 - val_loss: 0.0040\n",
      "Epoch 437/700\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 438/700\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0039 - val_loss: 0.0040\n",
      "Epoch 439/700\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 440/700\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0039 - val_loss: 0.0040\n",
      "Epoch 441/700\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 442/700\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 443/700\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 444/700\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 445/700\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 446/700\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 447/700\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 448/700\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 449/700\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 450/700\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 451/700\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 452/700\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 453/700\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 454/700\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 455/700\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 456/700\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 457/700\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 458/700\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 459/700\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 460/700\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 461/700\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 462/700\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 463/700\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 464/700\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 465/700\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 466/700\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 467/700\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 468/700\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 469/700\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 470/700\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 471/700\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 472/700\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 473/700\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 474/700\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 475/700\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 476/700\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 477/700\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 478/700\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 479/700\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 480/700\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 481/700\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 482/700\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 483/700\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 484/700\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 485/700\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 486/700\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 487/700\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 488/700\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 489/700\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 490/700\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 491/700\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 492/700\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 493/700\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 494/700\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 495/700\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 496/700\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 497/700\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 498/700\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 499/700\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 500/700\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 501/700\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 502/700\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 503/700\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 504/700\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 505/700\n",
      "1/1 [==============================] - 0s 140ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 506/700\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 507/700\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 508/700\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 509/700\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 510/700\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 511/700\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 512/700\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 513/700\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 514/700\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 515/700\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 516/700\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 517/700\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 518/700\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 519/700\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 520/700\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 521/700\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 522/700\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 523/700\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 524/700\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 525/700\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 526/700\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 527/700\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 528/700\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 529/700\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 530/700\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 531/700\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 532/700\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 533/700\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 534/700\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 535/700\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 536/700\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 537/700\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 538/700\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 539/700\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 540/700\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 541/700\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 542/700\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 543/700\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 544/700\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 545/700\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 546/700\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 547/700\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 548/700\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 549/700\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 550/700\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 551/700\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 552/700\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 553/700\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 554/700\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 555/700\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 556/700\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 557/700\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 558/700\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 559/700\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 560/700\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 561/700\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 562/700\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 563/700\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 564/700\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 565/700\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 566/700\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 567/700\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 568/700\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 569/700\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 570/700\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 571/700\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 572/700\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 573/700\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 574/700\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 575/700\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 576/700\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 577/700\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 578/700\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 579/700\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 580/700\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 581/700\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 582/700\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 583/700\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 584/700\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 585/700\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 586/700\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 587/700\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 588/700\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 589/700\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 590/700\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 591/700\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 592/700\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 593/700\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 594/700\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 595/700\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 596/700\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 597/700\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 598/700\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 599/700\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 600/700\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 601/700\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 602/700\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 603/700\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 604/700\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0039 - val_loss: 0.0040\n",
      "Epoch 605/700\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 606/700\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0039 - val_loss: 0.0040\n",
      "Epoch 607/700\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 608/700\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0039 - val_loss: 0.0040\n",
      "Epoch 609/700\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 610/700\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0039 - val_loss: 0.0040\n",
      "Epoch 611/700\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 612/700\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0039 - val_loss: 0.0040\n",
      "Epoch 613/700\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 614/700\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 615/700\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 616/700\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 617/700\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 618/700\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 619/700\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 620/700\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 621/700\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 622/700\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 623/700\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 624/700\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 625/700\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 626/700\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 627/700\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 628/700\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 629/700\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 630/700\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 631/700\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 632/700\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 633/700\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 634/700\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 635/700\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 636/700\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 637/700\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 638/700\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 639/700\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 640/700\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 641/700\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 642/700\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 643/700\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 644/700\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 645/700\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 646/700\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 647/700\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 648/700\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 649/700\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 650/700\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 651/700\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 652/700\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 653/700\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 654/700\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 655/700\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 656/700\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 657/700\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 658/700\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 659/700\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 660/700\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 661/700\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 662/700\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 663/700\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 664/700\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 665/700\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 666/700\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 667/700\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 668/700\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 669/700\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 670/700\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 671/700\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 672/700\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 673/700\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 674/700\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 675/700\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 676/700\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 677/700\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 678/700\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 679/700\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 680/700\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 681/700\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 682/700\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 683/700\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 684/700\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 685/700\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 686/700\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 687/700\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 688/700\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 689/700\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 690/700\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 691/700\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 692/700\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 693/700\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 694/700\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 695/700\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 696/700\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 697/700\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 698/700\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 699/700\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 700/700\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0038 - val_loss: 0.0039\n"
     ]
    }
   ],
   "source": [
    "history3 = model3.fit(\n",
    "    x=X_train,\n",
    "    y=y_train,\n",
    "    batch_size=X_train.shape[0],\n",
    "    epochs=700,\n",
    "    validation_data=(X_val, y_val),\n",
    "    shuffle=False,\n",
    "    steps_per_epoch=1,\n",
    "    validation_steps=1,\n",
    "    validation_batch_size=X_val.shape[0]\n",
    "   \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "WARNING:tensorflow:From C:\\Users\\Anna\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.0794 - val_loss: 0.9379\n",
      "Epoch 2/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.7817 - val_loss: 0.8373\n",
      "Epoch 3/500\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6214 - val_loss: 0.7522\n",
      "Epoch 4/500\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6977 - val_loss: 0.6596\n",
      "Epoch 5/500\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.5320 - val_loss: 0.5834\n",
      "Epoch 6/500\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.4432 - val_loss: 0.5141\n",
      "Epoch 7/500\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.4381 - val_loss: 0.4509\n",
      "Epoch 8/500\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.5111 - val_loss: 0.3836\n",
      "Epoch 9/500\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3521 - val_loss: 0.3337\n",
      "Epoch 10/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.2961 - val_loss: 0.2927\n",
      "Epoch 11/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.2245 - val_loss: 0.2598\n",
      "Epoch 12/500\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.2877 - val_loss: 0.2278\n",
      "Epoch 13/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.2939 - val_loss: 0.2010\n",
      "Epoch 14/500\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.2049 - val_loss: 0.1831\n",
      "Epoch 15/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.1591 - val_loss: 0.1694\n",
      "Epoch 16/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.1489 - val_loss: 0.1586\n",
      "Epoch 17/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1467 - val_loss: 0.1509\n",
      "Epoch 18/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.1552 - val_loss: 0.1444\n",
      "Epoch 19/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.1334 - val_loss: 0.1394\n",
      "Epoch 20/500\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.1343 - val_loss: 0.1357\n",
      "Epoch 21/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1260 - val_loss: 0.1324\n",
      "Epoch 22/500\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.1297 - val_loss: 0.1295\n",
      "Epoch 23/500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1265 - val_loss: 0.1273\n",
      "Epoch 24/500\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.1229 - val_loss: 0.1251\n",
      "Epoch 25/500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1211 - val_loss: 0.1234\n",
      "Epoch 26/500\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.1157 - val_loss: 0.1220\n",
      "Epoch 27/500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1212 - val_loss: 0.1206\n",
      "Epoch 28/500\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.1108 - val_loss: 0.1194\n",
      "Epoch 29/500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1164 - val_loss: 0.1182\n",
      "Epoch 30/500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1142 - val_loss: 0.1172\n",
      "Epoch 31/500\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.1116 - val_loss: 0.1163\n",
      "Epoch 32/500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1114 - val_loss: 0.1154\n",
      "Epoch 33/500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1120 - val_loss: 0.1145\n",
      "Epoch 34/500\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.1102 - val_loss: 0.1137\n",
      "Epoch 35/500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1126 - val_loss: 0.1128\n",
      "Epoch 36/500\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.1040 - val_loss: 0.1120\n",
      "Epoch 37/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.1018 - val_loss: 0.1112\n",
      "Epoch 38/500\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.1072 - val_loss: 0.1103\n",
      "Epoch 39/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1070 - val_loss: 0.1095\n",
      "Epoch 40/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.1059 - val_loss: 0.1087\n",
      "Epoch 41/500\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.1060 - val_loss: 0.1078\n",
      "Epoch 42/500\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.1000 - val_loss: 0.1070\n",
      "Epoch 43/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1080 - val_loss: 0.1062\n",
      "Epoch 44/500\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0991 - val_loss: 0.1054\n",
      "Epoch 45/500\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0947 - val_loss: 0.1046\n",
      "Epoch 46/500\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.1034 - val_loss: 0.1038\n",
      "Epoch 47/500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0978 - val_loss: 0.1030\n",
      "Epoch 48/500\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0932 - val_loss: 0.1022\n",
      "Epoch 49/500\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.1036 - val_loss: 0.1014\n",
      "Epoch 50/500\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0947 - val_loss: 0.1007\n",
      "Epoch 51/500\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0949 - val_loss: 0.0999\n",
      "Epoch 52/500\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0934 - val_loss: 0.0991\n",
      "Epoch 53/500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0940 - val_loss: 0.0984\n",
      "Epoch 54/500\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0918 - val_loss: 0.0976\n",
      "Epoch 55/500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0869 - val_loss: 0.0969\n",
      "Epoch 56/500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0962 - val_loss: 0.0961\n",
      "Epoch 57/500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0901 - val_loss: 0.0954\n",
      "Epoch 58/500\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0875 - val_loss: 0.0947\n",
      "Epoch 59/500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0941 - val_loss: 0.0939\n",
      "Epoch 60/500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0856 - val_loss: 0.0932\n",
      "Epoch 61/500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0898 - val_loss: 0.0925\n",
      "Epoch 62/500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0893 - val_loss: 0.0918\n",
      "Epoch 63/500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0915 - val_loss: 0.0911\n",
      "Epoch 64/500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0844 - val_loss: 0.0904\n",
      "Epoch 65/500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0867 - val_loss: 0.0897\n",
      "Epoch 66/500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0871 - val_loss: 0.0890\n",
      "Epoch 67/500\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0867 - val_loss: 0.0884\n",
      "Epoch 68/500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0849 - val_loss: 0.0877\n",
      "Epoch 69/500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0843 - val_loss: 0.0871\n",
      "Epoch 70/500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0819 - val_loss: 0.0864\n",
      "Epoch 71/500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0826 - val_loss: 0.0858\n",
      "Epoch 72/500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0776 - val_loss: 0.0851\n",
      "Epoch 73/500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0738 - val_loss: 0.0845\n",
      "Epoch 74/500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0843 - val_loss: 0.0839\n",
      "Epoch 75/500\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0835 - val_loss: 0.0833\n",
      "Epoch 76/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0759 - val_loss: 0.0826\n",
      "Epoch 77/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0774 - val_loss: 0.0820\n",
      "Epoch 78/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0900 - val_loss: 0.0814\n",
      "Epoch 79/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0738 - val_loss: 0.0808\n",
      "Epoch 80/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0843 - val_loss: 0.0802\n",
      "Epoch 81/500\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0731 - val_loss: 0.0797\n",
      "Epoch 82/500\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0814 - val_loss: 0.0791\n",
      "Epoch 83/500\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0767 - val_loss: 0.0785\n",
      "Epoch 84/500\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0746 - val_loss: 0.0779\n",
      "Epoch 85/500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0688 - val_loss: 0.0774\n",
      "Epoch 86/500\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0751 - val_loss: 0.0768\n",
      "Epoch 87/500\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0738 - val_loss: 0.0763\n",
      "Epoch 88/500\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0767 - val_loss: 0.0758\n",
      "Epoch 89/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0684 - val_loss: 0.0752\n",
      "Epoch 90/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0687 - val_loss: 0.0747\n",
      "Epoch 91/500\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0695 - val_loss: 0.0742\n",
      "Epoch 92/500\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0664 - val_loss: 0.0737\n",
      "Epoch 93/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0727 - val_loss: 0.0731\n",
      "Epoch 94/500\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0756 - val_loss: 0.0726\n",
      "Epoch 95/500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0674 - val_loss: 0.0721\n",
      "Epoch 96/500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0593 - val_loss: 0.0716\n",
      "Epoch 97/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0688 - val_loss: 0.0711\n",
      "Epoch 98/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0674 - val_loss: 0.0706\n",
      "Epoch 99/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0686 - val_loss: 0.0702\n",
      "Epoch 100/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0664 - val_loss: 0.0697\n",
      "Epoch 101/500\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0645 - val_loss: 0.0692\n",
      "Epoch 102/500\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0650 - val_loss: 0.0688\n",
      "Epoch 103/500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0618 - val_loss: 0.0683\n",
      "Epoch 104/500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0620 - val_loss: 0.0679\n",
      "Epoch 105/500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0676 - val_loss: 0.0674\n",
      "Epoch 106/500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0607 - val_loss: 0.0670\n",
      "Epoch 107/500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0636 - val_loss: 0.0665\n",
      "Epoch 108/500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0657 - val_loss: 0.0661\n",
      "Epoch 109/500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0639 - val_loss: 0.0656\n",
      "Epoch 110/500\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0652 - val_loss: 0.0652\n",
      "Epoch 111/500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0535 - val_loss: 0.0648\n",
      "Epoch 112/500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0594 - val_loss: 0.0644\n",
      "Epoch 113/500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0597 - val_loss: 0.0639\n",
      "Epoch 114/500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0688 - val_loss: 0.0635\n",
      "Epoch 115/500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0598 - val_loss: 0.0631\n",
      "Epoch 116/500\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0604 - val_loss: 0.0627\n",
      "Epoch 117/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0602 - val_loss: 0.0623\n",
      "Epoch 118/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0565 - val_loss: 0.0619\n",
      "Epoch 119/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0517 - val_loss: 0.0615\n",
      "Epoch 120/500\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0558 - val_loss: 0.0611\n",
      "Epoch 121/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0610 - val_loss: 0.0608\n",
      "Epoch 122/500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0575 - val_loss: 0.0604\n",
      "Epoch 123/500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0584 - val_loss: 0.0600\n",
      "Epoch 124/500\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0583 - val_loss: 0.0596\n",
      "Epoch 125/500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0558 - val_loss: 0.0592\n",
      "Epoch 126/500\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0599 - val_loss: 0.0589\n",
      "Epoch 127/500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0561 - val_loss: 0.0585\n",
      "Epoch 128/500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0565 - val_loss: 0.0582\n",
      "Epoch 129/500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0575 - val_loss: 0.0578\n",
      "Epoch 130/500\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0544 - val_loss: 0.0575\n",
      "Epoch 131/500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0508 - val_loss: 0.0571\n",
      "Epoch 132/500\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0465 - val_loss: 0.0568\n",
      "Epoch 133/500\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0609 - val_loss: 0.0564\n",
      "Epoch 134/500\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0521 - val_loss: 0.0561\n",
      "Epoch 135/500\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0516 - val_loss: 0.0558\n",
      "Epoch 136/500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0507 - val_loss: 0.0555\n",
      "Epoch 137/500\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0477 - val_loss: 0.0551\n",
      "Epoch 138/500\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0447 - val_loss: 0.0548\n",
      "Epoch 139/500\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0472 - val_loss: 0.0545\n",
      "Epoch 140/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0490 - val_loss: 0.0542\n",
      "Epoch 141/500\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0458 - val_loss: 0.0539\n",
      "Epoch 142/500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0486 - val_loss: 0.0536\n",
      "Epoch 143/500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0407 - val_loss: 0.0533\n",
      "Epoch 144/500\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0477 - val_loss: 0.0530\n",
      "Epoch 145/500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0500 - val_loss: 0.0527\n",
      "Epoch 146/500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0559 - val_loss: 0.0524\n",
      "Epoch 147/500\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0444 - val_loss: 0.0521\n",
      "Epoch 148/500\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0514 - val_loss: 0.0519\n",
      "Epoch 149/500\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0487 - val_loss: 0.0516\n",
      "Epoch 150/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0470 - val_loss: 0.0513\n",
      "Epoch 151/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0488 - val_loss: 0.0510\n",
      "Epoch 152/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0543 - val_loss: 0.0507\n",
      "Epoch 153/500\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0471 - val_loss: 0.0505\n",
      "Epoch 154/500\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0519 - val_loss: 0.0502\n",
      "Epoch 155/500\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0459 - val_loss: 0.0499\n",
      "Epoch 156/500\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0417 - val_loss: 0.0496\n",
      "Epoch 157/500\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0519 - val_loss: 0.0494\n",
      "Epoch 158/500\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0444 - val_loss: 0.0491\n",
      "Epoch 159/500\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0449 - val_loss: 0.0489\n",
      "Epoch 160/500\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0415 - val_loss: 0.0486\n",
      "Epoch 161/500\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0426 - val_loss: 0.0484\n",
      "Epoch 162/500\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0382 - val_loss: 0.0481\n",
      "Epoch 163/500\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0450 - val_loss: 0.0479\n",
      "Epoch 164/500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0465 - val_loss: 0.0476\n",
      "Epoch 165/500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0440 - val_loss: 0.0474\n",
      "Epoch 166/500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0429 - val_loss: 0.0471\n",
      "Epoch 167/500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0468 - val_loss: 0.0469\n",
      "Epoch 168/500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0520 - val_loss: 0.0467\n",
      "Epoch 169/500\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0375 - val_loss: 0.0464\n",
      "Epoch 170/500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0434 - val_loss: 0.0462\n",
      "Epoch 171/500\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0427 - val_loss: 0.0460\n",
      "Epoch 172/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0452 - val_loss: 0.0457\n",
      "Epoch 173/500\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0411 - val_loss: 0.0455\n",
      "Epoch 174/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0423 - val_loss: 0.0453\n",
      "Epoch 175/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0354 - val_loss: 0.0451\n",
      "Epoch 176/500\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0385 - val_loss: 0.0448\n",
      "Epoch 177/500\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0462 - val_loss: 0.0446\n",
      "Epoch 178/500\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0395 - val_loss: 0.0444\n",
      "Epoch 179/500\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0450 - val_loss: 0.0442\n",
      "Epoch 180/500\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0334 - val_loss: 0.0440\n",
      "Epoch 181/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0371 - val_loss: 0.0438\n",
      "Epoch 182/500\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0429 - val_loss: 0.0435\n",
      "Epoch 183/500\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0365 - val_loss: 0.0433\n",
      "Epoch 184/500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0365 - val_loss: 0.0431\n",
      "Epoch 185/500\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0331 - val_loss: 0.0429\n",
      "Epoch 186/500\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0360 - val_loss: 0.0427\n",
      "Epoch 187/500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0338 - val_loss: 0.0425\n",
      "Epoch 188/500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0384 - val_loss: 0.0423\n",
      "Epoch 189/500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0401 - val_loss: 0.0421\n",
      "Epoch 190/500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0352 - val_loss: 0.0419\n",
      "Epoch 191/500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0364 - val_loss: 0.0418\n",
      "Epoch 192/500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0340 - val_loss: 0.0416\n",
      "Epoch 193/500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0405 - val_loss: 0.0414\n",
      "Epoch 194/500\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0358 - val_loss: 0.0412\n",
      "Epoch 195/500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0405 - val_loss: 0.0410\n",
      "Epoch 196/500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0374 - val_loss: 0.0408\n",
      "Epoch 197/500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0376 - val_loss: 0.0407\n",
      "Epoch 198/500\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0357 - val_loss: 0.0405\n",
      "Epoch 199/500\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0320 - val_loss: 0.0403\n",
      "Epoch 200/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0360 - val_loss: 0.0401\n",
      "Epoch 201/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0357 - val_loss: 0.0400\n",
      "Epoch 202/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0394 - val_loss: 0.0398\n",
      "Epoch 203/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0398 - val_loss: 0.0396\n",
      "Epoch 204/500\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0400 - val_loss: 0.0395\n",
      "Epoch 205/500\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0330 - val_loss: 0.0393\n",
      "Epoch 206/500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0397 - val_loss: 0.0391\n",
      "Epoch 207/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0370 - val_loss: 0.0390\n",
      "Epoch 208/500\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0281 - val_loss: 0.0388\n",
      "Epoch 209/500\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0344 - val_loss: 0.0387\n",
      "Epoch 210/500\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0351 - val_loss: 0.0385\n",
      "Epoch 211/500\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0396 - val_loss: 0.0383\n",
      "Epoch 212/500\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0333 - val_loss: 0.0382\n",
      "Epoch 213/500\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0338 - val_loss: 0.0380\n",
      "Epoch 214/500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0301 - val_loss: 0.0379\n",
      "Epoch 215/500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0301 - val_loss: 0.0377\n",
      "Epoch 216/500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0425 - val_loss: 0.0376\n",
      "Epoch 217/500\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0286 - val_loss: 0.0374\n",
      "Epoch 218/500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0336 - val_loss: 0.0373\n",
      "Epoch 219/500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0374 - val_loss: 0.0371\n",
      "Epoch 220/500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0329 - val_loss: 0.0370\n",
      "Epoch 221/500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0316 - val_loss: 0.0368\n",
      "Epoch 222/500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0316 - val_loss: 0.0367\n",
      "Epoch 223/500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0318 - val_loss: 0.0366\n",
      "Epoch 224/500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0286 - val_loss: 0.0364\n",
      "Epoch 225/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0410 - val_loss: 0.0363\n",
      "Epoch 226/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0334 - val_loss: 0.0362\n",
      "Epoch 227/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0319 - val_loss: 0.0360\n",
      "Epoch 228/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0314 - val_loss: 0.0359\n",
      "Epoch 229/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0292 - val_loss: 0.0358\n",
      "Epoch 230/500\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0284 - val_loss: 0.0356\n",
      "Epoch 231/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0315 - val_loss: 0.0355\n",
      "Epoch 232/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0307 - val_loss: 0.0354\n",
      "Epoch 233/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0259 - val_loss: 0.0352\n",
      "Epoch 234/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0253 - val_loss: 0.0351\n",
      "Epoch 235/500\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0278 - val_loss: 0.0350\n",
      "Epoch 236/500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0279 - val_loss: 0.0349\n",
      "Epoch 237/500\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0292 - val_loss: 0.0347\n",
      "Epoch 238/500\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0282 - val_loss: 0.0346\n",
      "Epoch 239/500\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0290 - val_loss: 0.0345\n",
      "Epoch 240/500\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0317 - val_loss: 0.0344\n",
      "Epoch 241/500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0339 - val_loss: 0.0343\n",
      "Epoch 242/500\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0295 - val_loss: 0.0342\n",
      "Epoch 243/500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0291 - val_loss: 0.0341\n",
      "Epoch 244/500\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0312 - val_loss: 0.0340\n",
      "Epoch 245/500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0279 - val_loss: 0.0339\n",
      "Epoch 246/500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0352 - val_loss: 0.0337\n",
      "Epoch 247/500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0260 - val_loss: 0.0336\n",
      "Epoch 248/500\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0270 - val_loss: 0.0335\n",
      "Epoch 249/500\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0274 - val_loss: 0.0334\n",
      "Epoch 250/500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0404 - val_loss: 0.0333\n",
      "Epoch 251/500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0179 - val_loss: 0.0332\n",
      "Epoch 252/500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0261 - val_loss: 0.0331\n",
      "Epoch 253/500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0234 - val_loss: 0.0330\n",
      "Epoch 254/500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0406 - val_loss: 0.0330\n",
      "Epoch 255/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0252 - val_loss: 0.0328\n",
      "Epoch 256/500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0256 - val_loss: 0.0328\n",
      "Epoch 257/500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0296 - val_loss: 0.0327\n",
      "Epoch 258/500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0338 - val_loss: 0.0326\n",
      "Epoch 259/500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0222 - val_loss: 0.0325\n",
      "Epoch 260/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0223 - val_loss: 0.0324\n",
      "Epoch 261/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0223 - val_loss: 0.0323\n",
      "Epoch 262/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0327 - val_loss: 0.0322\n",
      "Epoch 263/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0203 - val_loss: 0.0321\n",
      "Epoch 264/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0257 - val_loss: 0.0320\n",
      "Epoch 265/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0345 - val_loss: 0.0319\n",
      "Epoch 266/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0243 - val_loss: 0.0318\n",
      "Epoch 267/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0229 - val_loss: 0.0317\n",
      "Epoch 268/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0215 - val_loss: 0.0316\n",
      "Epoch 269/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0347 - val_loss: 0.0315\n",
      "Epoch 270/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0229 - val_loss: 0.0314\n",
      "Epoch 271/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0265 - val_loss: 0.0313\n",
      "Epoch 272/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0287 - val_loss: 0.0313\n",
      "Epoch 273/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0249 - val_loss: 0.0312\n",
      "Epoch 274/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0257 - val_loss: 0.0311\n",
      "Epoch 275/500\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0233 - val_loss: 0.0310\n",
      "Epoch 276/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0232 - val_loss: 0.0309\n",
      "Epoch 277/500\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0237 - val_loss: 0.0308\n",
      "Epoch 278/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0212 - val_loss: 0.0307\n",
      "Epoch 279/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0231 - val_loss: 0.0306\n",
      "Epoch 280/500\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0277 - val_loss: 0.0305\n",
      "Epoch 281/500\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0222 - val_loss: 0.0304\n",
      "Epoch 282/500\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0243 - val_loss: 0.0303\n",
      "Epoch 283/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0207 - val_loss: 0.0302\n",
      "Epoch 284/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0225 - val_loss: 0.0302\n",
      "Epoch 285/500\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0283 - val_loss: 0.0301\n",
      "Epoch 286/500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0273 - val_loss: 0.0300\n",
      "Epoch 287/500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0263 - val_loss: 0.0299\n",
      "Epoch 288/500\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0294 - val_loss: 0.0298\n",
      "Epoch 289/500\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0312 - val_loss: 0.0298\n",
      "Epoch 290/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0220 - val_loss: 0.0297\n",
      "Epoch 291/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0245 - val_loss: 0.0296\n",
      "Epoch 292/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0210 - val_loss: 0.0295\n",
      "Epoch 293/500\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0228 - val_loss: 0.0295\n",
      "Epoch 294/500\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0256 - val_loss: 0.0294\n",
      "Epoch 295/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0204 - val_loss: 0.0293\n",
      "Epoch 296/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0238 - val_loss: 0.0293\n",
      "Epoch 297/500\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0205 - val_loss: 0.0292\n",
      "Epoch 298/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0199 - val_loss: 0.0291\n",
      "Epoch 299/500\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0244 - val_loss: 0.0291\n",
      "Epoch 300/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0255 - val_loss: 0.0290\n",
      "Epoch 301/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0211 - val_loss: 0.0289\n",
      "Epoch 302/500\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0318 - val_loss: 0.0289\n",
      "Epoch 303/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0284 - val_loss: 0.0288\n",
      "Epoch 304/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0237 - val_loss: 0.0288\n",
      "Epoch 305/500\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0232 - val_loss: 0.0287\n",
      "Epoch 306/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0194 - val_loss: 0.0287\n",
      "Epoch 307/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0180 - val_loss: 0.0286\n",
      "Epoch 308/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0290 - val_loss: 0.0285\n",
      "Epoch 309/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0268 - val_loss: 0.0285\n",
      "Epoch 310/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0190 - val_loss: 0.0284\n",
      "Epoch 311/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0191 - val_loss: 0.0284\n",
      "Epoch 312/500\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0249 - val_loss: 0.0283\n",
      "Epoch 313/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0233 - val_loss: 0.0282\n",
      "Epoch 314/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0299 - val_loss: 0.0282\n",
      "Epoch 315/500\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0266 - val_loss: 0.0281\n",
      "Epoch 316/500\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0306 - val_loss: 0.0280\n",
      "Epoch 317/500\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0269 - val_loss: 0.0280\n",
      "Epoch 318/500\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0241 - val_loss: 0.0279\n",
      "Epoch 319/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0202 - val_loss: 0.0278\n",
      "Epoch 320/500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0225 - val_loss: 0.0278\n",
      "Epoch 321/500\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0269 - val_loss: 0.0277\n",
      "Epoch 322/500\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0263 - val_loss: 0.0277\n",
      "Epoch 323/500\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0299 - val_loss: 0.0277\n",
      "Epoch 324/500\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0228 - val_loss: 0.0276\n",
      "Epoch 325/500\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0229 - val_loss: 0.0276\n",
      "Epoch 326/500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0275 - val_loss: 0.0275\n",
      "Epoch 327/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0182 - val_loss: 0.0275\n",
      "Epoch 328/500\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0237 - val_loss: 0.0274\n",
      "Epoch 329/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0166 - val_loss: 0.0274\n",
      "Epoch 330/500\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0269 - val_loss: 0.0273\n",
      "Epoch 331/500\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0191 - val_loss: 0.0273\n",
      "Epoch 332/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0256 - val_loss: 0.0272\n",
      "Epoch 333/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0243 - val_loss: 0.0272\n",
      "Epoch 334/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0190 - val_loss: 0.0271\n",
      "Epoch 335/500\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0245 - val_loss: 0.0271\n",
      "Epoch 336/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0255 - val_loss: 0.0270\n",
      "Epoch 337/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0246 - val_loss: 0.0270\n",
      "Epoch 338/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0194 - val_loss: 0.0269\n",
      "Epoch 339/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0239 - val_loss: 0.0269\n",
      "Epoch 340/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0191 - val_loss: 0.0268\n",
      "Epoch 341/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0229 - val_loss: 0.0268\n",
      "Epoch 342/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0150 - val_loss: 0.0267\n",
      "Epoch 343/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0204 - val_loss: 0.0267\n",
      "Epoch 344/500\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0201 - val_loss: 0.0266\n",
      "Epoch 345/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0168 - val_loss: 0.0266\n",
      "Epoch 346/500\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0215 - val_loss: 0.0265\n",
      "Epoch 347/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0213 - val_loss: 0.0265\n",
      "Epoch 348/500\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0201 - val_loss: 0.0264\n",
      "Epoch 349/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0236 - val_loss: 0.0264\n",
      "Epoch 350/500\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0262 - val_loss: 0.0263\n",
      "Epoch 351/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0214 - val_loss: 0.0263\n",
      "Epoch 352/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0250 - val_loss: 0.0263\n",
      "Epoch 353/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0175 - val_loss: 0.0262\n",
      "Epoch 354/500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0162 - val_loss: 0.0262\n",
      "Epoch 355/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0274 - val_loss: 0.0261\n",
      "Epoch 356/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0223 - val_loss: 0.0261\n",
      "Epoch 357/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0222 - val_loss: 0.0261\n",
      "Epoch 358/500\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0189 - val_loss: 0.0260\n",
      "Epoch 359/500\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0190 - val_loss: 0.0260\n",
      "Epoch 360/500\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0197 - val_loss: 0.0259\n",
      "Epoch 361/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0176 - val_loss: 0.0259\n",
      "Epoch 362/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0175 - val_loss: 0.0259\n",
      "Epoch 363/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0190 - val_loss: 0.0259\n",
      "Epoch 364/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0216 - val_loss: 0.0258\n",
      "Epoch 365/500\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0241 - val_loss: 0.0258\n",
      "Epoch 366/500\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0153 - val_loss: 0.0258\n",
      "Epoch 367/500\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0184 - val_loss: 0.0258\n",
      "Epoch 368/500\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0161 - val_loss: 0.0257\n",
      "Epoch 369/500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0269 - val_loss: 0.0257\n",
      "Epoch 370/500\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0235 - val_loss: 0.0257\n",
      "Epoch 371/500\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0207 - val_loss: 0.0256\n",
      "Epoch 372/500\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0186 - val_loss: 0.0256\n",
      "Epoch 373/500\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0235 - val_loss: 0.0256\n",
      "Epoch 374/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0128 - val_loss: 0.0255\n",
      "Epoch 375/500\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0203 - val_loss: 0.0255\n",
      "Epoch 376/500\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0228 - val_loss: 0.0255\n",
      "Epoch 377/500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0185 - val_loss: 0.0254\n",
      "Epoch 378/500\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0206 - val_loss: 0.0254\n",
      "Epoch 379/500\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0238 - val_loss: 0.0253\n",
      "Epoch 380/500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0151 - val_loss: 0.0253\n",
      "Epoch 381/500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0232 - val_loss: 0.0253\n",
      "Epoch 382/500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0225 - val_loss: 0.0252\n",
      "Epoch 383/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0221 - val_loss: 0.0252\n",
      "Epoch 384/500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0184 - val_loss: 0.0252\n",
      "Epoch 385/500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0184 - val_loss: 0.0251\n",
      "Epoch 386/500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0214 - val_loss: 0.0251\n",
      "Epoch 387/500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0166 - val_loss: 0.0250\n",
      "Epoch 388/500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0162 - val_loss: 0.0250\n",
      "Epoch 389/500\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0227 - val_loss: 0.0249\n",
      "Epoch 390/500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0277 - val_loss: 0.0249\n",
      "Epoch 391/500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0275 - val_loss: 0.0249\n",
      "Epoch 392/500\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0177 - val_loss: 0.0248\n",
      "Epoch 393/500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0251 - val_loss: 0.0248\n",
      "Epoch 394/500\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0164 - val_loss: 0.0248\n",
      "Epoch 395/500\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0166 - val_loss: 0.0248\n",
      "Epoch 396/500\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0164 - val_loss: 0.0247\n",
      "Epoch 397/500\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0216 - val_loss: 0.0247\n",
      "Epoch 398/500\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0172 - val_loss: 0.0247\n",
      "Epoch 399/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0170 - val_loss: 0.0247\n",
      "Epoch 400/500\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0171 - val_loss: 0.0246\n",
      "Epoch 401/500\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0192 - val_loss: 0.0246\n",
      "Epoch 402/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0257 - val_loss: 0.0246\n",
      "Epoch 403/500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0166 - val_loss: 0.0246\n",
      "Epoch 404/500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0175 - val_loss: 0.0245\n",
      "Epoch 405/500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0184 - val_loss: 0.0245\n",
      "Epoch 406/500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0212 - val_loss: 0.0245\n",
      "Epoch 407/500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0232 - val_loss: 0.0245\n",
      "Epoch 408/500\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0205 - val_loss: 0.0244\n",
      "Epoch 409/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0153 - val_loss: 0.0244\n",
      "Epoch 410/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0249 - val_loss: 0.0244\n",
      "Epoch 411/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0193 - val_loss: 0.0244\n",
      "Epoch 412/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0169 - val_loss: 0.0243\n",
      "Epoch 413/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0170 - val_loss: 0.0243\n",
      "Epoch 414/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0177 - val_loss: 0.0243\n",
      "Epoch 415/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0210 - val_loss: 0.0243\n",
      "Epoch 416/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0208 - val_loss: 0.0243\n",
      "Epoch 417/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0222 - val_loss: 0.0242\n",
      "Epoch 418/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0188 - val_loss: 0.0242\n",
      "Epoch 419/500\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0220 - val_loss: 0.0242\n",
      "Epoch 420/500\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0177 - val_loss: 0.0242\n",
      "Epoch 421/500\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0230 - val_loss: 0.0242\n",
      "Epoch 422/500\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0145 - val_loss: 0.0241\n",
      "Epoch 423/500\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0202 - val_loss: 0.0241\n",
      "Epoch 424/500\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0219 - val_loss: 0.0241\n",
      "Epoch 425/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0137 - val_loss: 0.0241\n",
      "Epoch 426/500\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0211 - val_loss: 0.0240\n",
      "Epoch 427/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0133 - val_loss: 0.0240\n",
      "Epoch 428/500\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0165 - val_loss: 0.0240\n",
      "Epoch 429/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0139 - val_loss: 0.0239\n",
      "Epoch 430/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0217 - val_loss: 0.0239\n",
      "Epoch 431/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0198 - val_loss: 0.0238\n",
      "Epoch 432/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0151 - val_loss: 0.0238\n",
      "Epoch 433/500\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0222 - val_loss: 0.0238\n",
      "Epoch 434/500\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0178 - val_loss: 0.0237\n",
      "Epoch 435/500\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0197 - val_loss: 0.0237\n",
      "Epoch 436/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0124 - val_loss: 0.0236\n",
      "Epoch 437/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0181 - val_loss: 0.0236\n",
      "Epoch 438/500\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0163 - val_loss: 0.0235\n",
      "Epoch 439/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0195 - val_loss: 0.0235\n",
      "Epoch 440/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0210 - val_loss: 0.0234\n",
      "Epoch 441/500\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0174 - val_loss: 0.0234\n",
      "Epoch 442/500\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0232 - val_loss: 0.0233\n",
      "Epoch 443/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0137 - val_loss: 0.0233\n",
      "Epoch 444/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0148 - val_loss: 0.0232\n",
      "Epoch 445/500\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0160 - val_loss: 0.0232\n",
      "Epoch 446/500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0213 - val_loss: 0.0231\n",
      "Epoch 447/500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0164 - val_loss: 0.0231\n",
      "Epoch 448/500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0189 - val_loss: 0.0230\n",
      "Epoch 449/500\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0171 - val_loss: 0.0230\n",
      "Epoch 450/500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0169 - val_loss: 0.0229\n",
      "Epoch 451/500\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0179 - val_loss: 0.0228\n",
      "Epoch 452/500\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0221 - val_loss: 0.0227\n",
      "Epoch 453/500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0183 - val_loss: 0.0226\n",
      "Epoch 454/500\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0220 - val_loss: 0.0225\n",
      "Epoch 455/500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0237 - val_loss: 0.0224\n",
      "Epoch 456/500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0164 - val_loss: 0.0224\n",
      "Epoch 457/500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0153 - val_loss: 0.0223\n",
      "Epoch 458/500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0194 - val_loss: 0.0223\n",
      "Epoch 459/500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0164 - val_loss: 0.0222\n",
      "Epoch 460/500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0138 - val_loss: 0.0222\n",
      "Epoch 461/500\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0141 - val_loss: 0.0221\n",
      "Epoch 462/500\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0194 - val_loss: 0.0221\n",
      "Epoch 463/500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0183 - val_loss: 0.0220\n",
      "Epoch 464/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0187 - val_loss: 0.0219\n",
      "Epoch 465/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0240 - val_loss: 0.0218\n",
      "Epoch 466/500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0109 - val_loss: 0.0217\n",
      "Epoch 467/500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0162 - val_loss: 0.0216\n",
      "Epoch 468/500\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0184 - val_loss: 0.0214\n",
      "Epoch 469/500\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0195 - val_loss: 0.0213\n",
      "Epoch 470/500\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0151 - val_loss: 0.0211\n",
      "Epoch 471/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0109 - val_loss: 0.0209\n",
      "Epoch 472/500\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0154 - val_loss: 0.0207\n",
      "Epoch 473/500\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0133 - val_loss: 0.0205\n",
      "Epoch 474/500\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0126 - val_loss: 0.0203\n",
      "Epoch 475/500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0130 - val_loss: 0.0200\n",
      "Epoch 476/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0170 - val_loss: 0.0198\n",
      "Epoch 477/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0133 - val_loss: 0.0196\n",
      "Epoch 478/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0143 - val_loss: 0.0193\n",
      "Epoch 479/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0122 - val_loss: 0.0191\n",
      "Epoch 480/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0121 - val_loss: 0.0190\n",
      "Epoch 481/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0127 - val_loss: 0.0188\n",
      "Epoch 482/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0151 - val_loss: 0.0187\n",
      "Epoch 483/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0149 - val_loss: 0.0187\n",
      "Epoch 484/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0147 - val_loss: 0.0187\n",
      "Epoch 485/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0177 - val_loss: 0.0186\n",
      "Epoch 486/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0150 - val_loss: 0.0185\n",
      "Epoch 487/500\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0209 - val_loss: 0.0183\n",
      "Epoch 488/500\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0131 - val_loss: 0.0182\n",
      "Epoch 489/500\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0129 - val_loss: 0.0180\n",
      "Epoch 490/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0115 - val_loss: 0.0178\n",
      "Epoch 491/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0118 - val_loss: 0.0177\n",
      "Epoch 492/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0148 - val_loss: 0.0175\n",
      "Epoch 493/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0164 - val_loss: 0.0173\n",
      "Epoch 494/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0196 - val_loss: 0.0172\n",
      "Epoch 495/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0109 - val_loss: 0.0171\n",
      "Epoch 496/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0127 - val_loss: 0.0170\n",
      "Epoch 497/500\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0155 - val_loss: 0.0169\n",
      "Epoch 498/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0126 - val_loss: 0.0168\n",
      "Epoch 499/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0155 - val_loss: 0.0166\n",
      "Epoch 500/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0139 - val_loss: 0.0164\n"
     ]
    }
   ],
   "source": [
    "# Для гипотезы 3\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
    "train_dataset = train_dataset.shuffle(buffer_size=len(X_train)).batch(256, drop_remainder=True)\n",
    "\n",
    "# Создайте tf.data.Dataset для валидационных данных\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((X_val, y_val))\n",
    "val_dataset = val_dataset.batch(256, drop_remainder=True)\n",
    "\n",
    "# Создайте и скомпилируйте модель\n",
    "model4.compile(\n",
    "    optimizer=tf.keras.optimizers.Nadam(learning_rate=0.005),\n",
    "    loss=tf.keras.losses.mean_squared_error,\n",
    ")\n",
    "\n",
    "# Обучите модель, используя tf.data.Dataset\n",
    "history4 = model4.fit(\n",
    "    train_dataset,\n",
    "    epochs=500,\n",
    "    validation_data=val_dataset,\n",
    "    steps_per_epoch=1,\n",
    "    validation_steps=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Для графика сверху пояснение***\n",
    "\n",
    "Ошибка уменьшилась быстро, а потом функции немного колеблются, возможно из-за того, что в датасете содержится много похожих данных.\n",
    "\n",
    "Модель начинает обучается на шуме и деталях в данных, которые не являются представительными для общего тренда. \n",
    "\n",
    "Если в датасете много схожих данных, модель может выучить эти шумы и потерять способность обобщения на новые, ранее не виденные данные."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkgAAAHHCAYAAABEEKc/AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAABXiUlEQVR4nO3deVxVZeIG8Ofce7n3sghXQMAFw0lzSZTcEGvGHElMs2gs0XRc0mzTVLJJnVyqKWway0xHs+lXzpSjo2OOmdkgmpXihlrpuJZbKiCi7NztvL8/7r0HLqAhAucgz/fzOR/gnPec+54TI8+825GEEAJEREREpNCpXQEiIiIirWFAIiIiIqqAAYmIiIioAgYkIiIiogoYkIiIiIgqYEAiIiIiqoABiYiIiKgCBiQiIiKiChiQiIiIiCpgQCKiW8Lp06chSRI++uijGz73q6++giRJ+Oqrr2q9XuXNmzcPkiTV6WcQUe1gQCIiqqa9e/di0qRJuPPOO+Hv74/WrVtj2LBhOH78uNpVI6JaZlC7AkREDcUbb7yBHTt24NFHH0WXLl2QmZmJxYsXo1u3bti1axc6d+6sdhWJqJYwIBERVVNycjJWrlwJo9Go7EtKSkJ0dDTmz5+Pjz/+WMXaEVFtYhcbEdUKz/ia48ePY9SoUQgKCkKzZs0we/ZsCCFw7tw5PPTQQwgMDERERAQWLFhQ6RrZ2dkYP348wsPDYTab0bVrV6xYsaJSuatXr2Ls2LEICgqCxWLBmDFjcPXq1SrrdfToUTzyyCMIDg6G2WxGjx49sGHDhhrdY58+fbzCEQC0a9cOd955J44cOVKjazocDrz66qu4/fbbYTKZEBUVhVmzZsFqtXqV27dvHxISEhAaGgpfX1+0adMGjz/+uFeZVatWoXv37mjSpAkCAwMRHR2Nd955p0b1ImrsGJCIqFYlJSVBlmXMnz8fsbGx+NOf/oSFCxfivvvuQ8uWLfHGG2+gbdu2mD59Or7++mvlvJKSEtx77734xz/+gZEjR+LNN99EUFAQxo4d6/VHXgiBhx56CP/4xz8watQo/OlPf8LPP/+MMWPGVKrL4cOH0bt3bxw5cgQzZszAggUL4O/vj8TERHz66ae1cr9CCGRlZSE0NLRG50+YMAFz5sxBt27d8Pbbb6Nv375ISUnB8OHDlTLZ2dkYMGAATp8+jRkzZuDdd9/FyJEjsWvXLqVMamoqRowYgaZNm+KNN97A/Pnzce+992LHjh03fY9EjZIgIqoFc+fOFQDExIkTlX0Oh0O0atVKSJIk5s+fr+y/cuWK8PX1FWPGjFH2LVy4UAAQH3/8sbLPZrOJuLg4ERAQIPLz84UQQqxfv14AEH/+85+9PufXv/61ACA+/PBDZX///v1FdHS0KC0tVfbJsiz69Okj2rVrp+zbtm2bACC2bdt2w/f9j3/8QwAQH3zwwS+W9Twjj4MHDwoAYsKECV7lpk+fLgCIrVu3CiGE+PTTTwUAsXfv3mtee8qUKSIwMFA4HI4bvgciqowtSERUqyZMmKB8r9fr0aNHDwghMH78eGW/xWJB+/bt8dNPPyn7Nm3ahIiICIwYMULZ5+Pjg+eeew6FhYXYvn27Us5gMODpp5/2+pzJkyd71SM3Nxdbt27FsGHDUFBQgJycHOTk5ODy5ctISEjAiRMncP78+Zu616NHj+LZZ59FXFxclS1Yv2TTpk0AXGObynv++ecBAJ9//jkA1/MCgI0bN8Jut1d5LYvFgqKiIqSmpt5wPYioMgYkIqpVrVu39vo5KCgIZrO5UhdUUFAQrly5ovx85swZtGvXDjqd9z9LHTt2VI57vjZv3hwBAQFe5dq3b+/188mTJyGEwOzZs9GsWTOvbe7cuQBcXVc1lZmZicGDByMoKAhr166FXq+/4WucOXMGOp0Obdu29dofEREBi8Wi3HPfvn0xdOhQvPzyywgNDcVDDz2EDz/80Guc0jPPPIM77rgD999/P1q1aoXHH38cmzdvrvH9ETV2nMVGRLWqqqBwrfAghKizesiyDACYPn06EhISqixTMZhUV15eHu6//35cvXoV33zzDVq0aFHjegL4xcUjJUnC2rVrsWvXLnz22Wf48ssv8fjjj2PBggXYtWsXAgICEBYWhoMHD+LLL7/EF198gS+++AIffvghRo8eXeVAdyK6PgYkItKE2267Dd9//z1kWfZqRTp69Khy3PM1LS0NhYWFXq1Ix44d87rer371KwCubrr4+Phaq2dpaSmGDBmC48ePY8uWLejUqVONr3XbbbdBlmWcOHFCaSkDgKysLFy9elW5Z4/evXujd+/eeO2117By5UqMHDkSq1atUro1jUYjhgwZgiFDhkCWZTzzzDN47733MHv27BqHQaLGil1sRKQJgwYNQmZmJlavXq3sczgcePfddxEQEIC+ffsq5RwOB5YuXaqUczqdePfdd72uFxYWhnvvvRfvvfceLl68WOnzLl26dMN1dDqdSEpKQnp6OtasWYO4uLgbvkZ5gwYNAgAsXLjQa/9bb70FABg8eDAA4MqVK5Va22JiYgBA6Wa7fPmy13GdTocuXbp4lSGi6mMLEhFpwsSJE/Hee+9h7NixyMjIQFRUFNauXYsdO3Zg4cKFaNKkCQBgyJAhuPvuuzFjxgycPn0anTp1wrp165CXl1fpmkuWLME999yD6OhoPPHEE/jVr36FrKwspKen4+eff8Z33313Q3V8/vnnsWHDBgwZMgS5ubmVFoYcNWrUDV2va9euGDNmDJYvX46rV6+ib9++2LNnD1asWIHExET069cPALBixQr89a9/xcMPP4zbb78dBQUFeP/99xEYGKiErAkTJiA3Nxe//e1v0apVK5w5cwbvvvsuYmJivFqniKia1J1ER0S3Cs8U9kuXLnntHzNmjPD3969Uvm/fvuLOO+/02peVlSXGjRsnQkNDhdFoFNHR0V7T9j0uX74sfv/734vAwEARFBQkfv/734sDBw5UmuYvhBA//vijGD16tIiIiBA+Pj6iZcuW4oEHHhBr165VylR3mn/fvn0FgGtuv6TiNH8hhLDb7eLll18Wbdq0ET4+PiIyMlLMnDnTa2mC/fv3ixEjRojWrVsLk8kkwsLCxAMPPCD27dunlFm7dq0YMGCACAsLE0ajUbRu3Vo8+eST4uLFi79YLyKqTBKiDkdJEhERETVAHINEREREVAEDEhEREVEFDEhEREREFTAgEREREVXAgERERERUAQMSERERUQVcKLKGZFnGhQsX0KRJk198jxIRERFpgxACBQUFaNGiRaWXY5fHgFRDFy5cQGRkpNrVICIioho4d+4cWrVqdc3jDEg15Hntwblz5xAYGKhybYiIiKg68vPzERkZqfwdvxYGpBrydKsFBgYyIBERETUwvzQ8hoO0iYiIiCpgQCIiIiKqgAGJiIiIqAKOQapjTqcTdrtd7Wo0OD4+PtDr9WpXg4iIGikGpDoihEBmZiauXr2qdlUaLIvFgoiICK4zRURE9Y4BqY54wlFYWBj8/Pz4R/4GCCFQXFyM7OxsAEDz5s1VrhERETU2DEh1wOl0KuEoJCRE7eo0SL6+vgCA7OxshIWFsbuNiIjqFQdp1wHPmCM/Pz+Va9KweZ4fx3AREVF9Y0CqQ+xWuzl8fkREpBYGJCIiIqIKGJCozkRFRWHhwoVqV4OIiOiGcZA2ebn33nsRExNTK8Fm79698Pf3v/lKERER1TMGJI2xO2UIIaDX6aDXaW8MjhACTqcTBsMv/+o0a9asHmpERERU+9jFpjHncotxNLMA+SX1P3Nr7Nix2L59O9555x1IkgRJkvDRRx9BkiR88cUX6N69O0wmE7799lv8+OOPeOihhxAeHo6AgAD07NkTW7Zs8bpexS42SZLwt7/9DQ8//DD8/PzQrl07bNiwoZ7vkoiI6JcxINUDIQSKbY5qbaV2GaV2J0pszmqfc71NCFHter7zzjuIi4vDE088gYsXL+LixYuIjIwEAMyYMQPz58/HkSNH0KVLFxQWFmLQoEFIS0vDgQMHMHDgQAwZMgRnz5697me8/PLLGDZsGL7//nsMGjQII0eORG5u7k09XyIiotrGLrZ6UGJ3otOcL1X57P+9kgA/Y/X+MwcFBcFoNMLPzw8REREAgKNHjwIAXnnlFdx3331K2eDgYHTt2lX5+dVXX8Wnn36KDRs2YNKkSdf8jLFjx2LEiBEAgNdffx2LFi3Cnj17MHDgwBu+NyIiorrCFiSqlh49enj9XFhYiOnTp6Njx46wWCwICAjAkSNHfrEFqUuXLsr3/v7+CAwMVF4pQkREpBVsQaoHvj56/O+VhGqVPZNTjAKrHS0tfmjq71Mrn10bKs5Gmz59OlJTU/GXv/wFbdu2ha+vLx555BHYbLbrXsfHx/ueJEmCLMu1UkciIqLawoBUDyRJqnY3l69RD7ssw9eoq/Y5tcloNMLpdP5iuR07dmDs2LF4+OGHAbhalE6fPl3HtSMiIqof7GIjL1FRUdi9ezdOnz6NnJyca7butGvXDuvWrcPBgwfx3Xff4bHHHmNLEBER3TIYkDTqBiaf1arp06dDr9ejU6dOaNas2TXHFL311lto2rQp+vTpgyFDhiAhIQHdunWr59oSERHVDUncyDxwUuTn5yMoKAh5eXkIDAz0OlZaWopTp06hTZs2MJvNN3Td0zlFyC+1o6XFFyEBptqscoNzM8+RiIioKtf7+10eW5A0hi+wJyIiUp8mAtKSJUsQFRUFs9mM2NhY7Nmz57rl16xZgw4dOsBsNiM6OhqbNm3yOj5v3jx06NAB/v7+aNq0KeLj47F7926vMlFRUcpq0Z5t/vz5tX5vRERE1PCoHpBWr16N5ORkzJ07F/v370fXrl2RkJBwzbVxdu7ciREjRmD8+PE4cOAAEhMTkZiYiEOHDill7rjjDixevBg//PADvv32W0RFRWHAgAG4dOmS17VeeeUVZcXoixcvYvLkyXV6rzeC/Z5ERETqUX0MUmxsLHr27InFixcDAGRZRmRkJCZPnowZM2ZUKp+UlISioiJs3LhR2de7d2/ExMRg2bJlVX6Gp79xy5Yt6N+/PwBXC9LUqVMxderUGtW7rsYgnblchLwSO1pYfBHKMUgcg0RERLWqQYxBstlsyMjIQHx8vLJPp9MhPj4e6enpVZ6Tnp7uVR4AEhISrlneZrNh+fLlCAoK8no1BgDMnz8fISEhuOuuu/Dmm2/C4XDc5B3dPA5BIiIiUp+qC0Xm5OTA6XQiPDzca394eLjyDrCKMjMzqyyfmZnptW/jxo0YPnw4iouL0bx5c6SmpiI0NFQ5/txzz6Fbt24IDg7Gzp07MXPmTFy8eBFvvfVWlZ9rtVphtVqVn/Pz82/oXqvPHZHYx0ZERKSaW3Yl7X79+uHgwYPIycnB+++/j2HDhmH37t0ICwsDACQnJytlu3TpAqPRiCeffBIpKSkwmSp3baWkpODll1+ut/ozHxEREalH1S620NBQ6PV6ZGVlee3PyspS3iZfUURERLXK+/v7o23btujduzc++OADGAwGfPDBB9esS2xsLBwOxzVflzFz5kzk5eUp27lz56pxhzXAPjYiIiLVqRqQjEYjunfvjrS0NGWfLMtIS0tDXFxclefExcV5lQeA1NTUa5Yvf93yXWQVHTx4EDqdTmlhqshkMiEwMNBrqwvMR0REROpTvYstOTkZY8aMQY8ePdCrVy8sXLgQRUVFGDduHABg9OjRaNmyJVJSUgAAU6ZMQd++fbFgwQIMHjwYq1atwr59+7B8+XIAQFFREV577TU8+OCDaN68OXJycrBkyRKcP38ejz76KADXQO/du3ejX79+aNKkCdLT0zFt2jSMGjUKTZs2VedBVNIwO9ludnYgERGRFqgekJKSknDp0iXMmTMHmZmZiImJwebNm5WB2GfPnoVOV9bQ1adPH6xcuRIvvfQSZs2ahXbt2mH9+vXo3LkzAECv1+Po0aNYsWIFcnJyEBISgp49e+Kbb77BnXfeCcDVGrRq1SrMmzcPVqsVbdq0wbRp07zGJREREVHjpfo6SA1VXa2DdC63GFeKbYgIMiOsScNb+6c2W5C4DhIREdW2BrEOEmnL8uXL0aJFC8iy7LX/oYcewuOPP44ff/wRDz30EMLDwxEQEICePXtiy5YtKtWWiIio7jAg1QchAFtRtTadvRiSvbja5X9xu4EGwkcffRSXL1/Gtm3blH25ubnYvHkzRo4cicLCQgwaNAhpaWk4cOAABg4ciCFDhuDs2bN18dSIiIhUo/oYpEbBXgy83qJaRVu6t1oz6wJg9K9W0aZNm+L+++/HypUrlVeyrF27FqGhoejXrx90Op3XauSvvvoqPv30U2zYsAGTJk2qzVoTERGpii1I5GXkyJH497//rSyJ8Mknn2D48OHQ6XQoLCzE9OnT0bFjR1gsFgQEBODIkSNsQSIiolsOW5Dqg4+fqyWnGs5fLUFukQ1hgSaE18YgbR+/Gyo+ZMgQCCHw+eefK7P/3n77bQDA9OnTkZqair/85S9o27YtfH198cgjj8Bms918PYmIiDSEAak+SFK1u7mEjwThYwB8zICx/mdumc1m/O53v8Mnn3yCkydPon379ujWrRsAYMeOHRg7diwefvhhAEBhYeE1Vx4nIiJqyBiQNEYLK2mPHDkSDzzwAA4fPoxRo0Yp+9u1a4d169ZhyJAhkCQJs2fPrjTjjYiI6FbAMUia44pIai5O9dvf/hbBwcE4duwYHnvsMWX/W2+9haZNm6JPnz4YMmQIEhISlNYlIiKiWwlbkLTG04SkYkLS6XS4cKHymKmoqChs3brVa9+zzz7r9TO73IiI6FbAFiQiIiKiChiQNKZsDBLfAENERKQWBiQiIiKiChiQNIrtR0REROphQKpD4gbeg0aV8fkREZFaGJDqgI+PDwCguLj4hs/VwjpIWuF5fp7nSUREVF84zb8O6PV6WCwWZGdnAwD8/PwgSdWLPna7FcJhg90GlJY2zrgkhEBxcTGys7NhsVig1+vVrhIRETUyDEh1JCIiAgCUkFRdeSV2FJQ6UGI2oMi3cbecWCwW5TkSERHVJwakOiJJEpo3b46wsDDY7fZqn7f865+weu8FDO3WCs/0a1OHNdQ2Hx8fthwREZFqGJDqmF6vv6E/9CWyDucLnCh06GA21//LaomIiIiDtDWn7E0jnMFFRESkFgYkjdG5B3NzhjsREZF6GJA0xjPZjWsAERERqYcBSWPKutiIiIhILQxIWuNuQpLZgkRERKQaBiSN0SldbOrWg4iIqDFjQNIYyd3JxnxERESkHgYkjZHYgkRERKQ6BiSN0XEWGxERkeoYkDRG4jpIREREqmNA0iiupE1ERKQeBiSN8YxBkpmPiIiIVMOApDF81QgREZH6GJA0hi+rJSIiUh8DksZIfNcIERGR6hiQNEbHV40QERGpjgFJoxiPiIiI1MOApDFcB4mIiEh9DEga4xmCxC42IiIi9TAgaYzyqhF1q0FERNSoMSBpjCQxIREREalNEwFpyZIliIqKgtlsRmxsLPbs2XPd8mvWrEGHDh1gNpsRHR2NTZs2eR2fN28eOnToAH9/fzRt2hTx8fHYvXu3V5nc3FyMHDkSgYGBsFgsGD9+PAoLC2v93m5U2UraTEhERERqUT0grV69GsnJyZg7dy7279+Prl27IiEhAdnZ2VWW37lzJ0aMGIHx48fjwIEDSExMRGJiIg4dOqSUueOOO7B48WL88MMP+PbbbxEVFYUBAwbg0qVLSpmRI0fi8OHDSE1NxcaNG/H1119j4sSJdX6/v4SDtImIiNQnCaHun+LY2Fj07NkTixcvBgDIsozIyEhMnjwZM2bMqFQ+KSkJRUVF2Lhxo7Kvd+/eiImJwbJly6r8jPz8fAQFBWHLli3o378/jhw5gk6dOmHv3r3o0aMHAGDz5s0YNGgQfv75Z7Ro0eIX6+25Zl5eHgIDA2ty61X6eNcZvLT+EBLuDMd7v+9Ra9clIiKi6v/9VrUFyWazISMjA/Hx8co+nU6H+Ph4pKenV3lOenq6V3kASEhIuGZ5m82G5cuXIygoCF27dlWuYbFYlHAEAPHx8dDpdJW64jysVivy8/O9trqgDEFiCxIREZFqVA1IOTk5cDqdCA8P99ofHh6OzMzMKs/JzMysVvmNGzciICAAZrMZb7/9NlJTUxEaGqpcIywszKu8wWBAcHDwNT83JSUFQUFByhYZGXlD91pdEjwradfJ5YmIiKgaVB+DVFf69euHgwcPYufOnRg4cCCGDRt2zXFN1TFz5kzk5eUp27lz52qxtmU80/w5jY2IiEg9qgak0NBQ6PV6ZGVlee3PyspCREREledERERUq7y/vz/atm2L3r1744MPPoDBYMAHH3ygXKNiWHI4HMjNzb3m55pMJgQGBnptdYFdbEREROpTNSAZjUZ0794daWlpyj5ZlpGWloa4uLgqz4mLi/MqDwCpqanXLF/+ularVbnG1atXkZGRoRzfunUrZFlGbGxsTW+nVpR1sTEhERERqcWgdgWSk5MxZswY9OjRA7169cLChQtRVFSEcePGAQBGjx6Nli1bIiUlBQAwZcoU9O3bFwsWLMDgwYOxatUq7Nu3D8uXLwcAFBUV4bXXXsODDz6I5s2bIycnB0uWLMH58+fx6KOPAgA6duyIgQMH4oknnsCyZctgt9sxadIkDB8+vFoz2OoS14kkIiJSn+oBKSkpCZcuXcKcOXOQmZmJmJgYbN68WRmIffbsWeh0ZQ1dffr0wcqVK/HSSy9h1qxZaNeuHdavX4/OnTsDAPR6PY4ePYoVK1YgJycHISEh6NmzJ7755hvceeedynU++eQTTJo0Cf3794dOp8PQoUOxaNGi+r35KnAdJCIiIvWpvg5SQ1VX6yD9O+NnPL/mO/zmjmb4++O9au26RERE1EDWQaLKygZpM7cSERGphQFJY3TsYiMiIlIdA5LGlA3SZkIiIiJSCwOSRsmy2jUgIiJqvBiQNEbpYmMLEhERkWoYkDSGK2kTERGpjwFJYzwraTMgERERqYcBSWM4SJuIiEh9DEgao2MXGxERkeoYkDTHM0ibiIiI1MKApDGeLjaZTUhERESqYUDSGK6kTUREpD4GJI1xNyCxi42IiEhFDEgaw5fVEhERqY8BSWO4UCQREZH6GJA0RuKrRoiIiFTHgKQxyhgk5iMiIiLVMCBpjKcFSWZAIiIiUg0DksboOEibiIhIdQxIGiMpnWxERESkFgYkjeFK2kREROpjQNIYDtImIiJSHwOSxpRN8yciIiK1MCBpDLvYiIiI1MeApDHKEG3mIyIiItUwIGmMTscuNiIiIrUxIGlM2SBtRiQiIiK1MCBpTNkYJHXrQURE1JgxIGkOX1ZLRESkNgYkjSl71Yi69SAiImrMGJA0RlkHiQGJiIhINQxIGsNB2kREROpjQNIYHVfSJiIiUh0DksZIHINERESkOgYkjeKrRoiIiNTDgKQxSguSutUgIiJq1BiQNEbHWWxERESqY0DSmLIxSExIREREamFA0hgJnMVGRESkNgYkjdGxBYmIiEh1mghIS5YsQVRUFMxmM2JjY7Fnz57rll+zZg06dOgAs9mM6OhobNq0STlmt9vx4osvIjo6Gv7+/mjRogVGjx6NCxcueF0jKioKkiR5bfPnz6+T+7sRHKRNRESkPtUD0urVq5GcnIy5c+di//796Nq1KxISEpCdnV1l+Z07d2LEiBEYP348Dhw4gMTERCQmJuLQoUMAgOLiYuzfvx+zZ8/G/v37sW7dOhw7dgwPPvhgpWu98soruHjxorJNnjy5Tu+1elwJSZYZkYiIiNQiCZX7cmJjY9GzZ08sXrwYACDLMiIjIzF58mTMmDGjUvmkpCQUFRVh48aNyr7evXsjJiYGy5Ytq/Iz9u7di169euHMmTNo3bo1AFcL0tSpUzF16tQa1Ts/Px9BQUHIy8tDYGBgja5RlR8vFaL/gu1oYjbgh3kJtXZdIiIiqv7fb1VbkGw2GzIyMhAfH6/s0+l0iI+PR3p6epXnpKene5UHgISEhGuWB4C8vDxIkgSLxeK1f/78+QgJCcFdd92FN998Ew6H45rXsFqtyM/P99rqgo59bERERKozqPnhOTk5cDqdCA8P99ofHh6Oo0ePVnlOZmZmleUzMzOrLF9aWooXX3wRI0aM8EqKzz33HLp164bg4GDs3LkTM2fOxMWLF/HWW29VeZ2UlBS8/PLLN3J7NeJ5WS1X0iYiIlKPqgGprtntdgwbNgxCCCxdutTrWHJysvJ9ly5dYDQa8eSTTyIlJQUmk6nStWbOnOl1Tn5+PiIjI2u9zmxAIiIiUp+qASk0NBR6vR5ZWVle+7OyshAREVHlOREREdUq7wlHZ86cwdatW39xnFBsbCwcDgdOnz6N9u3bVzpuMpmqDE61jStpExERqU/VMUhGoxHdu3dHWlqask+WZaSlpSEuLq7Kc+Li4rzKA0BqaqpXeU84OnHiBLZs2YKQkJBfrMvBgweh0+kQFhZWw7upXexiIyIiUo/qXWzJyckYM2YMevTogV69emHhwoUoKirCuHHjAACjR49Gy5YtkZKSAgCYMmUK+vbtiwULFmDw4MFYtWoV9u3bh+XLlwNwhaNHHnkE+/fvx8aNG+F0OpXxScHBwTAajUhPT8fu3bvRr18/NGnSBOnp6Zg2bRpGjRqFpk2bqvMg3NjFRkREpD7VA1JSUhIuXbqEOXPmIDMzEzExMdi8ebMyEPvs2bPQ6coauvr06YOVK1fipZdewqxZs9CuXTusX78enTt3BgCcP38eGzZsAADExMR4fda2bdtw7733wmQyYdWqVZg3bx6sVivatGmDadOmeY0xUovEhERERKQ61ddBaqjqah2ki3kliEvZCh+9hBOvDaq16xIREVEDWQeJKvO8rJYLaRMREamHAUljJL6sloiISHUMSBrDIUhERETqY0DSmCZps/CZcRb6SgfUrgoREVGjxYCkMfqrPyFadxrBKGA3GxERkUoYkLRG0gMAdJLgatpEREQqYUDSGveaTzrIXE2biIhIJQxIGiPpXC1IeshwMiARERGpggFJY8oHJFlWuTJERESNFAOS1njGILEFiYiISDUMSBrj1cXG5bSJiIhUwYCkMZIySFtwmj8REZFKGJA0xtOCpGMLEhERkWoYkDRG0hkAcBYbERGRmhiQtEYqtw4SZ7ERERGpggFJa7gOEhERkeoYkLTG3YKkl2TIHINERESkCgYkrXGvgyRB8FUjREREKmFA0hqug0RERKQ6BiStkcq9aoQtSERERKpgQNIaXdksNidnsREREamCAUlrJHaxERERqY0BSWs8s9jYxUZERKQaBiSt0XEWGxERkdoYkLSGXWxERESqY0DSGh1nsREREamNAUlrJM5iIyIiUhsDktZwkDYREZHqGJC0xt3FpuO72IiIiFTDgKQ17kHaOgg42YJERESkCgYkreG72IiIiFTHgKQ1SgsSxyARERGphQFJa3Rlg7Q5i42IiEgdDEhaw1lsREREqmNA0pryXWwcg0RERKQKBiSt0XEWGxERkdpqFJBWrFiBzz//XPn5D3/4AywWC/r06YMzZ87UWuUaJb6LjYiISHU1Ckivv/46fH19AQDp6elYsmQJ/vznPyM0NBTTpk2r1Qo2OjrOYiMiIlKboSYnnTt3Dm3btgUArF+/HkOHDsXEiRNx99134957763N+jU+5QdpcxYbERGRKmrUghQQEIDLly8DAP773//ivvvuAwCYzWaUlJTUXu0aI09AkmSOQSIiIlJJjQLSfffdhwkTJmDChAk4fvw4Bg0aBAA4fPgwoqKibvh6S5YsQVRUFMxmM2JjY7Fnz57rll+zZg06dOgAs9mM6OhobNq0STlmt9vx4osvIjo6Gv7+/mjRogVGjx6NCxcueF0jNzcXI0eORGBgICwWC8aPH4/CwsIbrnut03EWGxERkdpqFJCWLFmCuLg4XLp0Cf/+978REhICAMjIyMCIESNu6FqrV69GcnIy5s6di/3796Nr165ISEhAdnZ2leV37tyJESNGYPz48Thw4AASExORmJiIQ4cOAQCKi4uxf/9+zJ49G/v378e6detw7NgxPPjgg17XGTlyJA4fPozU1FRs3LgRX3/9NSZOnFiDp1HL+C42IiIi1UlCqPtXODY2Fj179sTixYsBALIsIzIyEpMnT8aMGTMqlU9KSkJRURE2btyo7OvduzdiYmKwbNmyKj9j79696NWrF86cOYPWrVvjyJEj6NSpE/bu3YsePXoAADZv3oxBgwbh559/RosWLX6x3vn5+QgKCkJeXh4CAwNrcutVO/YF8M/hOCjfjh/uX4ffx0XV3rWJiIgauer+/a5RC9LmzZvx7bffKj8vWbIEMTExeOyxx3DlypVqX8dmsyEjIwPx8fFlFdLpEB8fj/T09CrPSU9P9yoPAAkJCdcsDwB5eXmQJAkWi0W5hsViUcIRAMTHx0On02H37t1VXsNqtSI/P99rqxPuMUg6TvMnIiJSTY0C0gsvvKAEhB9++AHPP/88Bg0ahFOnTiE5Obna18nJyYHT6UR4eLjX/vDwcGRmZlZ5TmZm5g2VLy0txYsvvogRI0YoSTEzMxNhYWFe5QwGA4KDg695nZSUFAQFBSlbZGRkte7xhpVbB4n5iIiISB01CkinTp1Cp06dAAD//ve/8cADD+D111/HkiVL8MUXX9RqBW+G3W7HsGHDIITA0qVLb+paM2fORF5enrKdO3eulmpZga6sBYnrIBEREamjRusgGY1GFBcXAwC2bNmC0aNHAwCCg4NvqOspNDQUer0eWVlZXvuzsrIQERFR5TkRERHVKu8JR2fOnMHWrVu9+hkjIiIqDQJ3OBzIzc295ueaTCaYTKZq31uNcSVtIiIi1dWoBemee+5BcnIyXn31VezZsweDBw8GABw/fhytWrWq9nWMRiO6d++OtLQ0ZZ8sy0hLS0NcXFyV58TFxXmVB4DU1FSv8p5wdOLECWzZskWZZVf+GlevXkVGRoayb+vWrZBlGbGxsdWuf53gu9iIiIhUV6OAtHjxYhgMBqxduxZLly5Fy5YtAQBffPEFBg4ceEPXSk5Oxvvvv48VK1bgyJEjePrpp1FUVIRx48YBAEaPHo2ZM2cq5adMmYLNmzdjwYIFOHr0KObNm4d9+/Zh0qRJAFzh6JFHHsG+ffvwySefwOl0IjMzE5mZmbDZbACAjh07YuDAgXjiiSewZ88e7NixA5MmTcLw4cOrNYOtTklcB4mIiEhtNepia926tdc0e4+33377hq+VlJSES5cuYc6cOcjMzERMTAw2b96sDMQ+e/YsdLqyHNenTx+sXLkSL730EmbNmoV27dph/fr16Ny5MwDg/Pnz2LBhAwAgJibG67O2bdumvArlk08+waRJk9C/f3/odDoMHToUixYtuuH617ryrxphPiIiIlJFjddBcjqdWL9+PY4cOQIAuPPOO/Hggw9Cr9fXagW1qs7WQfp5H/C3/vhZhGLNPV9g2n131N61iYiIGrnq/v2uUQvSyZMnMWjQIJw/fx7t27cH4JoGHxkZic8//xy33357zWpNXusgcRYbERGROmo0Bum5557D7bffjnPnzmH//v3Yv38/zp49izZt2uC5556r7To2LjrOYiMiIlJbjVqQtm/fjl27diE4OFjZFxISgvnz5+Puu++utco1SnwXGxERkepq1IJkMplQUFBQaX9hYSGMRuNNV6pRK9/FxhYkIiIiVdQoID3wwAOYOHEidu/eDSEEhBDYtWsXnnrqKTz44IO1XcfGRcdXjRAREamtRgFp0aJFuP322xEXFwez2Qyz2Yw+ffqgbdu2WLhwYS1XsZEptw4SxyARERGpo0ZjkCwWC/7zn//g5MmTyjT/jh07om3btrVauUZJV34dJAYkIiIiNVQ7ICUnJ1/3+LZt25Tv33rrrZrXqLHju9iIiIhUV+2AdODAgWqVkySpxpUhKIO0JQi2IBEREamk2gGpfAsR1aHyg7RlletCRETUSNVokDbVIXcXm0GSuQ4SERGRShiQtEZX9i474XSqWBEiIqLGiwFJa8oFJFkwIBEREamBAUlrdOWGhTkd6tWDiIioEWNA0pryAUkwIBEREamBAUlrygUk4bCrWBEiIqLGiwFJa6Ryg7RltiARERGpgQFJa3Q6CPd/FsExSERERKpgQNIg2dPNxhYkIiIiVTAgaZCQXAGJLUhERETqYEDSIOFZC4ktSERERKpgQNIg4R6oLWQuFElERKQGBiQNEu4xSBJbkIiIiFTBgKRFErvYiIiI1MSApEGeFiQ4uVAkERGRGhiQtEjn4/rKl9USERGpggFJgziLjYiISF0MSFqkDNJmCxIREZEaGJC0yDMGSXAMEhERkRoYkLTI3cXGFiQiIiJ1MCBpkOTpYuMgbSIiIlUwIGmROyDpOEibiIhIFQxIWqSMQWJAIiIiUgMDkgZJetc6SHzVCBERkToYkLRIzzFIREREamJA0iDPIG09ZMiyULk2REREjQ8DkgZJ7hYkA5xwMCARERHVOwYkDSprQXLCyYBERERU7xiQNKisBUmGQ5ZVrg0REVHjo3pAWrJkCaKiomA2mxEbG4s9e/Zct/yaNWvQoUMHmM1mREdHY9OmTV7H161bhwEDBiAkJASSJOHgwYOVrnHvvfdCkiSv7amnnqrN27opZQHJwRYkIiIiFagakFavXo3k5GTMnTsX+/fvR9euXZGQkIDs7Owqy+/cuRMjRozA+PHjceDAASQmJiIxMRGHDh1SyhQVFeGee+7BG2+8cd3PfuKJJ3Dx4kVl+/Of/1yr93YzPF1sBsiwOxmQiIiI6puqAemtt97CE088gXHjxqFTp05YtmwZ/Pz88H//939Vln/nnXcwcOBAvPDCC+jYsSNeffVVdOvWDYsXL1bK/P73v8ecOXMQHx9/3c/28/NDRESEsgUGBtbqvd0MzzpIHINERESkDtUCks1mQ0ZGhleQ0el0iI+PR3p6epXnpKenVwo+CQkJ1yx/PZ988glCQ0PRuXNnzJw5E8XFxTd8jTrjaUGSOAaJiIhIDQa1PjgnJwdOpxPh4eFe+8PDw3H06NEqz8nMzKyyfGZm5g199mOPPYbbbrsNLVq0wPfff48XX3wRx44dw7p16655jtVqhdVqVX7Oz8+/oc+8IZzFRkREpCrVApKaJk6cqHwfHR2N5s2bo3///vjxxx9x++23V3lOSkoKXn755fqpoK78LDYGJCIiovqmWhdbaGgo9Ho9srKyvPZnZWUhIiKiynMiIiJuqHx1xcbGAgBOnjx5zTIzZ85EXl6esp07d+6mPvO6dHoAbEEiIiJSi2oByWg0onv37khLS1P2ybKMtLQ0xMXFVXlOXFycV3kASE1NvWb56vIsBdC8efNrljGZTAgMDPTa6oyu3EranMVGRERU71TtYktOTsaYMWPQo0cP9OrVCwsXLkRRURHGjRsHABg9ejRatmyJlJQUAMCUKVPQt29fLFiwAIMHD8aqVauwb98+LF++XLlmbm4uzp49iwsXLgAAjh07BgDKbLUff/wRK1euxKBBgxASEoLvv/8e06ZNw29+8xt06dKlnp/ANZQLSGxBIiIiqn+qBqSkpCRcunQJc+bMQWZmJmJiYrB582ZlIPbZs2eh05U1cvXp0wcrV67ESy+9hFmzZqFdu3ZYv349OnfurJTZsGGDErAAYPjw4QCAuXPnYt68eTAajdiyZYsSxiIjIzF06FC89NJL9XTX1VBukLads9iIiIjqnSSEYBNFDeTn5yMoKAh5eXm13932zVtA2sv4l6Mv2kz4CD2jgmv3+kRERI1Udf9+q/6qEaqCpwVJ4hgkIiIiNTAgaZE7IPlwDBIREZEqGJC0yP2qEQOcXEmbiIhIBQxIWqQ3AgB84GAXGxERkQoYkLTIHZBMsLMFiYiISAUMSFpk8LQgOWF1MCARERHVNwYkLXK3IBklO+zsYiMiIqp3DEhaVG4Mko0tSERERPWOAUmLygUku5MBiYiIqL4xIGmRp4uNLUhERESqYEDSIoMJgDsgsQWJiIio3jEgaZF7oUjXIG0GJCIiovrGgKRFelcLEgdpExERqYMBSYs8LUgcpE1ERKQKBiQtMrAFiYiISE0MSFrkedWIxIBERESkBgYkLXIHJABwOmwqVoSIiKhxYkDSonIBSXZYVawIERFR48SApEXlAhIYkIiIiOodA5IW6Q2Q3f9pZDu72IiIiOobA5JGCZ1rqr/sZEAiIiKqbwxIGiV7utnYxUZERFTvGJA0Sna3IIEtSERERPWOAUmjhLsFSTAgERER1TsGJI0SOldAkhx2lWtCRETU+DAgaZVnDJLMFiQiIqL6xoCkVXpPCxIDEhERUX1jQNIooXcN0pZkzmIjIiKqbwxIGiX5+AIADAxIRERE9Y4BSat8/AEABmeJyhUhIiJqfBiQNEoy+QEADM5SCCFUrg0REVHjwoCkUXqjKyD5wgqrQ1a5NkRERI0LA5JG6U2uLjZfyYoSm1Pl2hARETUuDEgapXO3IJlhQ7GdAYmIiKg+MSBpldHVguQHtiARERHVNwYkrXJP8/eFFaVsQSIiIqpXDEha5eMepC1ZUcwWJCIionrFgKRVnoAEG0rYgkRERFSvGJC0yt3FxjFIRERE9Y8BSavKdbGV2B0qV4aIiKhxUT0gLVmyBFFRUTCbzYiNjcWePXuuW37NmjXo0KEDzGYzoqOjsWnTJq/j69atw4ABAxASEgJJknDw4MFK1ygtLcWzzz6LkJAQBAQEYOjQocjKyqrN27p55ab5l9i4UCQREVF9UjUgrV69GsnJyZg7dy7279+Prl27IiEhAdnZ2VWW37lzJ0aMGIHx48fjwIEDSExMRGJiIg4dOqSUKSoqwj333IM33njjmp87bdo0fPbZZ1izZg22b9+OCxcu4He/+12t399Ncbcg+aEUxTa2IBEREdUnSaj4oq/Y2Fj07NkTixcvBgDIsozIyEhMnjwZM2bMqFQ+KSkJRUVF2Lhxo7Kvd+/eiImJwbJly7zKnj59Gm3atMGBAwcQExOj7M/Ly0OzZs2wcuVKPPLIIwCAo0ePomPHjkhPT0fv3r2rVff8/HwEBQUhLy8PgYGBN3rrvyzzELDsblwSQVjdNw2Tftuu9j+DiIiokanu32/VWpBsNhsyMjIQHx9fVhmdDvHx8UhPT6/ynPT0dK/yAJCQkHDN8lXJyMiA3W73uk6HDh3QunXrG7pOnTOWtSBxFhsREVH9Mqj1wTk5OXA6nQgPD/faHx4ejqNHj1Z5TmZmZpXlMzMzq/25mZmZMBqNsFgsN3Qdq9UKq9Wq/Jyfn1/tz6wRswUA4C9ZUVruc4mIiKjuqT5Iu6FISUlBUFCQskVGRtbtB5qDlG/l4it1+1lERETkRbWAFBoaCr1eX2n2WFZWFiIiIqo8JyIi4obKX+saNpsNV69evaHrzJw5E3l5ecp27ty5an9mjej0sBmaAACcRbl1+1lERETkRbWAZDQa0b17d6SlpSn7ZFlGWloa4uLiqjwnLi7OqzwApKamXrN8Vbp37w4fHx+v6xw7dgxnz5697nVMJhMCAwO9trpmN7pakdiCREREVL9UG4MEAMnJyRgzZgx69OiBXr16YeHChSgqKsK4ceMAAKNHj0bLli2RkpICAJgyZQr69u2LBQsWYPDgwVi1ahX27duH5cuXK9fMzc3F2bNnceHCBQCu8AO4Wo4iIiIQFBSE8ePHIzk5GcHBwQgMDMTkyZMRFxdX7Rls9UU2W4Din6Ervap2VYiIiBoVVQNSUlISLl26hDlz5iAzMxMxMTHYvHmzMhD77Nmz0OnKGrn69OmDlStX4qWXXsKsWbPQrl07rF+/Hp07d1bKbNiwQQlYADB8+HAAwNy5czFv3jwAwNtvvw2dToehQ4fCarUiISEBf/3rX+vhjm+Qe6C2zpqnbj2IiIgaGVXXQWrI6nwdJABFH4+C/8nP8Lo8FrNeeadOPoOIiKgx0fw6SPTLDP7BAABfZwGsDq6FREREVF8YkDTMGBACALBIhcgrsatcGyIiosaDAUnDpEDXsgMRUi7yGZCIiIjqDQOSlllaAwBaSZeQW8SAREREVF8YkLTMchsAoJWUgwtXS1SuDBERUePBgKRlFtfrTJpKhci6lK1yZYiIiBoPBiQtMzVBicG1mnZx9imVK0NERNR4MCBpXFHg7QAAv8s/qFwTIiKixoMBSeNsLXoBAFrkf6dyTYiIiBoPBiSNs3T4DQCglyMD57M4DomIiKg+MCBpnF/73yJbF4Zw6SqavX8X8EEC8P2/AFlWu2pERES3LAYkrfPxxTed/4QcEQijoxA4twtY9wSKP3gAKLmidu2IiIhuSQxIDcCgBx7BxJAVGGx9DW/ah6FImOB3fgdyFvWDs4ghiYiIqLZJQgihdiUaouq+Dbi2WB1O7D11BVdLbMjY/Q0m/jwDzaVcHPeNwe3J/4Xex1TndSAiImroqvv3mwGphuo7IFWUtn0rYrc+hgCpBAct96HrpE8gGRiSiIiIrqe6f7/ZxdZA9e/7W/zvnkVwCB1irqbi1IL+KLh8Xu1qERER3RIYkBqwXvcNw86e7yJf+OJXJT+g+N1f47vdW9WuFhERUYPHgNTA/eaBUTjzu89wRmqJcFxG+03DkPbFWrWrRURE1KAxIN0Corv2ROjUb3E0IBZmyY7YXc/ii/9+oXa1iIiIGiwGpFuEf1Aw2k/5D04F9kCAVIq7djyNr/bx9SREREQ1wYB0C5F8fBH1zDpkmaIQIV1B08/GIePkBbWrRURE1OAwIN1iJHMQQiasQ6GuCbpKPyLz44k4mZWvdrWIiIgaFAakW5Ch2e3wGf4POKHDYHyD9OVTkJVfqna1iIiIGgwGpFuU6Y5+KBn4FgDg98512LLkOVxiSCIiIqoWBqRbWEDvcbja548AgJHW1fhu0aO4kJWlcq2IiIi0jwHpFmcZ8Afk9E2BEzrEO76GtLQPTmf8V+1qERERaRoDUiMQ2u8Z5A7bgAtSBJojB5EbhuGntS8BslPtqhEREWkSA1Ij0azTr+H/XDq+8hsAvSTwq0Pv4uK7A4D8i2pXjYiISHMYkBqRoKbBuPv51fhnq9koFGY0v7IPee/+Bo7M/6ldNSIiIk1hQGpkfPQ6DB//PD7r/U+ckFsiyJ6N0uUDYP1ph9pVIyIi0gwGpEZIkiSMuP+3OPPgWhwQ7RAgF0D394fg2LtC7aoRERFpAgNSIxbfoxNsIz7Ff+We8IEdhs+fg/yf5wBbkdpVIyIiUhUDUiMX2yESppGf4B3nowAA3YEVEO/9Bji/X+WaERERqYcBidC3fTg6jXgNv7f/ERdFMKTLJyE+uA/4ZgGXAiAiokaJAYkAAPd1CsfIEaORKP8Zm5y9IMkOIO0VYMUQ4Oo5tatHRERUrxiQSDGwcwQ+eGoAXvV9ES/YJ6IIZuDMDmDZ3cCRjWpXj4iIqN4wIJGXzi2D8J/J9+DHlom435qCg/LtQGkesHoksOkFwGFVu4pERER1jgGJKglrYsY/J/bG4L59kGSfi/ccg10H9iwHPnkEKM1Xt4JERER1jAGJqmQy6PHiwA741zN9sTb4STxum45CYQZOfQ35w0FAQabaVSQiIqozDEh0XV0jLdj43D3o2PdRjHTMxiURCF3WD3C8Hw9c/lHt6hEREdUJTQSkJUuWICoqCmazGbGxsdizZ891y69ZswYdOnSA2WxGdHQ0Nm3a5HVcCIE5c+agefPm8PX1RXx8PE6cOOFVJioqCpIkeW3z58+v9Xu7FZgMeryQ0AGzn3gMEwyv45QcDkP+OdjfHwBc/E7t6hEREdU61QPS6tWrkZycjLlz52L//v3o2rUrEhISkJ2dXWX5nTt3YsSIERg/fjwOHDiAxMREJCYm4tChQ0qZP//5z1i0aBGWLVuG3bt3w9/fHwkJCSgtLfW61iuvvIKLFy8q2+TJk+v0Xhu6HlHBWDJpKGZa3sQhOQo+pTmwf3A/cOobtatGRERUqyQhhFCzArGxsejZsycWL14MAJBlGZGRkZg8eTJmzJhRqXxSUhKKioqwcWPZtPPevXsjJiYGy5YtgxACLVq0wPPPP4/p06cDAPLy8hAeHo6PPvoIw4cPB+BqQZo6dSqmTp1ao3rn5+cjKCgIeXl5CAwMrNE1GqoiqwOz/vktRvw0A711R+CQfCDFz4M+7hlAp3rmJiIiuqbq/v1W9a+ZzWZDRkYG4uPjlX06nQ7x8fFIT0+v8pz09HSv8gCQkJCglD916hQyMzO9ygQFBSE2NrbSNefPn4+QkBDcddddePPNN+FwOK5ZV6vVivz8fK+tsfI3GfD26L7YGfceNjl7wSDs0Kf+EaXLfgv8vE/t6hEREd00VQNSTk4OnE4nwsPDvfaHh4cjM7PqWVKZmZnXLe/5+kvXfO6557Bq1Sps27YNTz75JF5//XX84Q9/uGZdU1JSEBQUpGyRkZHVv9FbkE4nIfn+rnAO/QivYAIKhC/M2QeAv/WHfc0TwIWDgPPagZOIiEjLDGpXQC3JycnK9126dIHRaMSTTz6JlJQUmEymSuVnzpzpdU5+fn6jD0kAMCSmJbpH/Qmz1tyHX5/5K4YZtsPn8L+Aw/+Cw+APhLSFISQKaBoFWG4Dmt4GBLYEAsIB36aAJKl9C0RERJWoGpBCQ0Oh1+uRlZXltT8rKwsRERFVnhMREXHd8p6vWVlZaN68uVeZmJiYa9YlNjYWDocDp0+fRvv27SsdN5lMVQYnAlpYfLFoQgK2HLkLT322AUMLVyJWdwSBjiIg6zvXVgVZ5wPh1wy6JmGQAsKBgDDAP9QVnHybAmZL2feezceXoYqIiOqcqgHJaDSie/fuSEtLQ2JiIgDXIO20tDRMmjSpynPi4uKQlpbmNbg6NTUVcXFxAIA2bdogIiICaWlpSiDKz8/H7t278fTTT1+zLgcPHoROp0NYWFit3FtjI0kS7usUjt92mIC0I0Mw74fzuHLmMPR5pxEpZaO1lI1W0iW0lrIRJl1FU6kQOtkOFF5wbdUk9CYIXwsk32BIvpYKAcriHa58/ACDETCYAb0JMJTbPD8zbBERURVU72JLTk7GmDFj0KNHD/Tq1QsLFy5EUVERxo0bBwAYPXo0WrZsiZSUFADAlClT0LdvXyxYsACDBw/GqlWrsG/fPixfvhyA6w/11KlT8ac//Qnt2rVDmzZtMHv2bLRo0UIJYenp6di9ezf69euHJk2aID09HdOmTcOoUaPQtGlTVZ7DrUKvkzDgzggMuDMCQHcU2xw4m1uMM5eLcSa3GF9fLsa5K8XIzSuEsyAbhpJshCAPzaQ8hOEKmkqFCJIKYUERLFIhglCk/OwjOSE5rZAKs4DCrF+sS3UIvStASe6vVYYor5/N5UKX8Ro/X6fMtc5jUCMi0hTVA1JSUhIuXbqEOXPmIDMzEzExMdi8ebMyyPrs2bPQlZs63qdPH6xcuRIvvfQSZs2ahXbt2mH9+vXo3LmzUuYPf/gDioqKMHHiRFy9ehX33HMPNm/eDLPZDMDVXbZq1SrMmzcPVqsVbdq0wbRp07zGGFHt8DMa0CEiEB0iqp5K6XDKyC2yIbvAikuFVlwttiG3yI7TxTbkFtlwpdiGK0V2XCmyorQoHyi5An+5wB2aChEkFcGihKhCWKSyYGWCDUbJARNsMMEBE+wwSXavz5ecNsBpq49HcX3XDF9VBbby5SqEOGMAYGri+mr0c7Wi+fgBRn/3FuD6mcsxEBFdl+rrIDVUjXkdJDUJIVBkc+KKOzzlFtlwtdheFqbcgarQ6kCp3YlShwyr3QmrQ3b9bHPA6bABjlL4CDtMsMMoub/CUS5U2WGEXQlVZcfd+6Wy40Y4YJJsyvGqrlEW1OyusFYhqNU7H3/AFFAWmowBlX82+rtathxW19gwvxAgsAVgbOIKYZ7NGMDARUQNRnX/fqvegkR0IyRJQoDJgACTAZHBfjW+jhACNqesBCer3R2g7DKsDlegsjrK/WwvV9Yho8jhxOVrHPOc731uWTmbUwYgygWqqkJXxWBWFrqUFrFy5T1Bzg+laIJi+Eul8IUNvrDCV7LCD1b4oxQ6yf3/h+xFrq22+Pi7A1NAWYuVj5+7FcsdxjwzF32bugbkB0W6xo2ZAgGdvvbqQkRUCxiQqFGSJAkmgx4mgx6BZp96/WxZFl5BymqXUVouSFUZ0uwVQpdDRr5S1ruVzHVe2T5POCt1OKB3WhGAUvhJpQhACfxQCn/JCn+UwF8qhT9K4YdSBEil8EcJBCQ4oUe4dAVNUYBgKR9NpBL4w3W+j+R03ZQncBXW4IFIOlfrlDkIMPgCfk1drVTmQMA32BWo/DwD8YMBv2BXWU9Ll4+5Vv/7EBEBDEhE9U6nk+Br1MPXWP+tJg6njCKrE4U2BwpLHSi0OlBkdX1Vvi91IM/mwHn38fwSOwpKHSgodSC/1PV9odUBQMAEuyssSSUIgCs4+UlW+KEUfkrrVSkCpWKEIg8hUgGaSgUIQR6aS7kwS3ZAyEDRJddWEzqfstYrYxNXgPJt6gpYRvd+c5CrjI+fa+yWp6yPexyXj7lct6Ie0POfRqLGjv8KEDUiBr0OQX46BPndXKuZUxYoKLUjv8QVmvJKXFt+SbnvS+3IK3HgrHt/+WMO2dXVZ4QdQShCqJSHAJTAV7IiGAUIkErQBCUIkgoRDFeocg3IL0RTqRCBKIJJcq/ULtuBklzXVhskvStEmQPdwSrQ1VVoCiwLWgaza00uH79yg+iNZYPo9T6uljGdoWy/p8XLtymXmCBqABiQiOiG6XUSLH5GWPyMN3yuEAIldieuFNuRW2jD5SIrcotcA+49LVWFVjtOe1qwSh0oLNdyVWx1deuZYIMZNgSgBE2kEgSgGAFSKYLcsxkDUaR0GzaRitEEJfCDFWbJNTYrQHJ1MRrhgFmywQDZXUFnWZdhwcXafGxl9EZXa5VnpqKPvyuElZ/B6AlZep+ykOXjW1bW0xpWabaj0RXMdAbXuQZf136d3j2r0dcVAnV6hjSi62BAIqJ6JUkS/IwG+BkNaGnxveHzPd2E+aWu2YqeQOUJV56f80pd3YT55Y57yheU2mF3lp/A6+ouDEAJzLDBV7KiCUoQKBW7xmp5gpYyAN4KE+zwdYctE+zwgQNGyQE/WGGCDQY4YZCcruvBBhNs0HsGyTttQInKy0tIOu8lIAxm1z4P2Qk4SgGn3fUVcLWg+QW7xowFhLlbw9xjwJw2wF7q6jLV+5QLdH7utb50rkAm6Vzdop4wVz4Y6o2uc/RG1zUgueqm93GFOknnWuKCqB4wIBFRg1Jb3YSldidKbE4U250otjpQbHOiyOZqoSq/r9jm+epEptVR4ZjrHM8MRbtThs09U9Epe6+goocTRtjRBCWwSIWuMCbZlADlJ5XC7F4KwhPSfOBUlofwkRwwwwazeyajWbKXHYMDJsm1GWGHAU74wAEDnNd+AEIGbIWurbqKc4DcH2v4xGtR+QVWdT6uUGUwub73hDO9yTWWTOdpgTO61w1zBzGdj+u4pHed4wltnu5TU4C79c1d3lPO06KnN7pa4cq30Anh+qozAPCEQT1naTZQDEhE1CiZffQw++hRV2vnO2UBq8MVwhyygEMWyCu240qxDUVWB0rsTqVVy+aebVhkdSLP6kCOU4bd6ZrtWGJ3oMjqhFMWsDtlZbC8zT1b8Zfo3WFJBwEfOOCPUmUJCTNsSpejEXboIGCAE3rIkCAgIMEgOZXvzbAhEMXwlawIgGtgvl6SoYcMHWQISJDcS1h4QprZvUaYUXJC5y5nhBNGyQEfuDajO+T5wFG9h+soLWvVaij0Ru+WMiVo+ZTrEq2wX+9Tthhs+a5XTwjTGdxdpbqynz3dpzp9uSBncHenSuU+v9xnKi197v/ToXMHS0+wkyRXENTpXddoJN2zDEhERHVAryvrSvSoSZfi9QghUGqXlVYum1OGw+kKUlaHjBKbE04hIMvC1dpldcAuy7A7ZHdLmBOFVgccsgyn7FqCwlPeKQScsoDN/dUpA7IQOCcLXCqwotTuRF6JHQXugCdJgI9OB1kIyEJAwNWgcoN3BAkCPnCFMh1kV8hyt4p5uixdrWSyq1Wu3CKsRnfI8pFcLW+un10tdz7lFm/1KRfQXC17ZWHNJNnh6x7f5mqVs8Pgvo7BvVU7yJWnlVX7a4unq9QT1jzdoOXHv3la7pRxcp4xduVa+JRXMPmUGzfnnl2afx64e4qrW1cFDEhERA2UJJUtGRGiYj0cThl6nQRJkuB5OYNDdgUrq11Gsd0BR7kxXzanqzvSE+ZK3WuB2R2y0trmcJexO12By9Wi5oTNUdZ9WWp3osjmhBBlq+zn2xzuz3Bdw+bu+nQKAYe7Vc5qd7XqycL1WZ4yskClrtGqCaWVTQ8ZZtggucOd3t1SZ5AckOCaqenpOjVJrnDmowQyJwxwwCA5vfYb3MHQR/K0sJX7KjnKBTXX+XrIrpY/d2te+SDn+aqTXOPs9HAqLYU+cNZ8VX8hA04rrteLWxtEm99Aatu/bj/kGhiQiIjophj0ZYO7JXfXi49ego/e1ZUZhPpdjLWmnLJwtco5ZBSWul5X5JBlCAEU25xKS5tD9gQvAad7n93pGnsmlwtYrn1lLXKeRWEdzrLrWO0y7LIMmyzgFIDNvRCsqy5QVvy3OWT3eUIJmLI7GLoCpStsAq6WO4fsOl49rlY7nXsmp6vlzgk9nJChU8KbSbJB7z7mmYighwyD5Cz7vkJ4M0oOpdWufMjzKde6Z4IdBslzvkNp+TsvQtHqvEDftrX8H7qaGJCIiIjg6hYFJATodQgwNew/j+W7ST0tcE53y5ynNa18l6yn1c7mbsWTJLjHvZWFQKcQsLvHvrn2ucKZ3Vl2XVkWsHmu6b5uiUPGFYcMm8OpXNNaLgjalW5hJxxOT5euwJViG9bf3kO1Z9iwfwOIiIioEp1Ogg6uVryGyuaQ3aFVHQxIREREpDlGg+6XC9UhdT+diIiISIMYkIiIiIgqYEAiIiIiqoABiYiIiKgCBiQiIiKiChiQiIiIiCpgQCIiIiKqgAGJiIiIqAIGJCIiIqIKGJCIiIiIKmBAIiIiIqqAAYmIiIioAgYkIiIiogoMalegoRJCAADy8/NVrgkRERFVl+fvtufv+LUwINVQQUEBACAyMlLlmhAREdGNKigoQFBQ0DWPS+KXIhRVSZZlXLhwAU2aNIEkSbV23fz8fERGRuLcuXMIDAystes2JI39GTT2+wf4DBr7/QN8Bo39/oG6ewZCCBQUFKBFixbQ6a490ogtSDWk0+nQqlWrOrt+YGBgo/0fhUdjfwaN/f4BPoPGfv8An0Fjv3+gbp7B9VqOPDhIm4iIiKgCBiQiIiKiChiQNMZkMmHu3LkwmUxqV0U1jf0ZNPb7B/gMGvv9A3wGjf3+AfWfAQdpExEREVXAFiQiIiKiChiQiIiIiCpgQCIiIiKqgAGJiIiIqAIGJI1ZsmQJoqKiYDabERsbiz179qhdpVrx9ddfY8iQIWjRogUkScL69eu9jgshMGfOHDRv3hy+vr6Ij4/HiRMnvMrk5uZi5MiRCAwMhMViwfjx41FYWFiPd1FzKSkp6NmzJ5o0aYKwsDAkJibi2LFjXmVKS0vx7LPPIiQkBAEBARg6dCiysrK8ypw9exaDBw+Gn58fwsLC8MILL8DhcNTnrdTY0qVL0aVLF2XRt7i4OHzxxRfK8Vv9/iuaP38+JEnC1KlTlX23+jOYN28eJEny2jp06KAcv9XvHwDOnz+PUaNGISQkBL6+voiOjsa+ffuU47f6v4VRUVGVfgckScKzzz4LQGO/A4I0Y9WqVcJoNIr/+7//E4cPHxZPPPGEsFgsIisrS+2q3bRNmzaJP/7xj2LdunUCgPj000+9js+fP18EBQWJ9evXi++++048+OCDok2bNqKkpEQpM3DgQNG1a1exa9cu8c0334i2bduKESNG1POd1ExCQoL48MMPxaFDh8TBgwfFoEGDROvWrUVhYaFS5qmnnhKRkZEiLS1N7Nu3T/Tu3Vv06dNHOe5wOETnzp1FfHy8OHDggNi0aZMIDQ0VM2fOVOOWbtiGDRvE559/Lo4fPy6OHTsmZs2aJXx8fMShQ4eEELf+/Ze3Z88eERUVJbp06SKmTJmi7L/Vn8HcuXPFnXfeKS5evKhsly5dUo7f6vefm5srbrvtNjF27Fixe/du8dNPP4kvv/xSnDx5Uilzq/9bmJ2d7fXfPzU1VQAQ27ZtE0Jo63eAAUlDevXqJZ599lnlZ6fTKVq0aCFSUlJUrFXtqxiQZFkWERER4s0331T2Xb16VZhMJvHPf/5TCCHE//73PwFA7N27VynzxRdfCEmSxPnz5+ut7rUlOztbABDbt28XQrju18fHR6xZs0Ypc+TIEQFApKenCyFcIVOn04nMzEylzNKlS0VgYKCwWq31ewO1pGnTpuJvf/tbo7r/goIC0a5dO5Gamir69u2rBKTG8Azmzp0runbtWuWxxnD/L774orjnnnuuebwx/ls4ZcoUcfvttwtZljX3O8AuNo2w2WzIyMhAfHy8sk+n0yE+Ph7p6ekq1qzunTp1CpmZmV73HhQUhNjYWOXe09PTYbFY0KNHD6VMfHw8dDoddu/eXe91vll5eXkAgODgYABARkYG7Ha71zPo0KEDWrdu7fUMoqOjER4erpRJSEhAfn4+Dh8+XI+1v3lOpxOrVq1CUVER4uLiGtX9P/vssxg8eLDXvQKN53fgxIkTaNGiBX71q19h5MiROHv2LIDGcf8bNmxAjx498OijjyIsLAx33XUX3n//feV4Y/u30Gaz4eOPP8bjjz8OSZI09zvAgKQROTk5cDqdXv/RASA8PByZmZkq1ap+eO7veveemZmJsLAwr+MGgwHBwcEN7vnIsoypU6fi7rvvRufOnQG47s9oNMJisXiVrfgMqnpGnmMNwQ8//ICAgACYTCY89dRT+PTTT9GpU6dGc/+rVq3C/v37kZKSUulYY3gGsbGx+Oijj7B582YsXboUp06dwq9//WsUFBQ0ivv/6aefsHTpUrRr1w5ffvklnn76aTz33HNYsWIFgMb3b+H69etx9epVjB07FoD2/jdgqNWrEdEvevbZZ3Ho0CF8++23alel3rVv3x4HDx5EXl4e1q5dizFjxmD79u1qV6tenDt3DlOmTEFqairMZrPa1VHF/fffr3zfpUsXxMbG4rbbbsO//vUv+Pr6qliz+iHLMnr06IHXX38dAHDXXXfh0KFDWLZsGcaMGaNy7erfBx98gPvvvx8tWrRQuypVYguSRoSGhkKv11carZ+VlYWIiAiValU/PPd3vXuPiIhAdna213GHw4Hc3NwG9XwmTZqEjRs3Ytu2bWjVqpWyPyIiAjabDVevXvUqX/EZVPWMPMcaAqPRiLZt26J79+5ISUlB165d8c477zSK+8/IyEB2dja6desGg8EAg8GA7du3Y9GiRTAYDAgPD7/ln0FFFosFd9xxB06ePNkofgeaN2+OTp06ee3r2LGj0s3YmP4tPHPmDLZs2YIJEyYo+7T2O8CApBFGoxHdu3dHWlqask+WZaSlpSEuLk7FmtW9Nm3aICIiwuve8/PzsXv3buXe4+LicPXqVWRkZChltm7dClmWERsbW+91vlFCCEyaNAmffvoptm7dijZt2ngd7969O3x8fLyewbFjx3D27FmvZ/DDDz94/eOYmpqKwMDASv/oNhSyLMNqtTaK++/fvz9++OEHHDx4UNl69OiBkSNHKt/f6s+gosLCQvz4449o3rx5o/gduPvuuyst73H8+HHcdtttABrHv4UeH374IcLCwjB48GBln+Z+B2p1yDfdlFWrVgmTySQ++ugj8b///U9MnDhRWCwWr9H6DVVBQYE4cOCAOHDggAAg3nrrLXHgwAFx5swZIYRraqvFYhH/+c9/xPfffy8eeuihKqe23nXXXWL37t3i22+/Fe3atWswU1uffvppERQUJL766iuvKa7FxcVKmaeeekq0bt1abN26Vezbt0/ExcWJuLg45bhneuuAAQPEwYMHxebNm0WzZs0azBTnGTNmiO3bt4tTp06J77//XsyYMUNIkiT++9//CiFu/fuvSvlZbELc+s/g+eefF1999ZU4deqU2LFjh4iPjxehoaEiOztbCHHr3/+ePXuEwWAQr732mjhx4oT45JNPhJ+fn/j444+VMrf6v4VCuGZot27dWrz44ouVjmnpd4ABSWPeffdd0bp1a2E0GkWvXr3Erl271K5Srdi2bZsAUGkbM2aMEMI1vXX27NkiPDxcmEwm0b9/f3Hs2DGva1y+fFmMGDFCBAQEiMDAQDFu3DhRUFCgwt3cuKruHYD48MMPlTIlJSXimWeeEU2bNhV+fn7i4YcfFhcvXvS6zunTp8X9998vfH19RWhoqHj++eeF3W6v57upmccff1zcdtttwmg0imbNmon+/fsr4UiIW//+q1IxIN3qzyApKUk0b95cGI1G0bJlS5GUlOS1BtCtfv9CCPHZZ5+Jzp07C5PJJDp06CCWL1/udfxW/7dQCCG+/PJLAaDSfQmhrd8BSQghardNioiIiKhh4xgkIiIiogoYkIiIiIgqYEAiIiIiqoABiYiIiKgCBiQiIiKiChiQiIiIiCpgQCIiIiKqgAGJiKgWfPXVV5AkqdJ7pIioYWJAIiIiIqqAAYmIiIioAgYkIrolyLKMlJQUtGnTBr6+vujatSvWrl0LoKz76/PPP0eXLl1gNpvRu3dvHDp0yOsa//73v3HnnXfCZDIhKioKCxYs8DputVrx4osvIjIyEiaTCW3btsUHH3zgVSYjIwM9evSAn58f+vTpU+nt7UTUMDAgEdEtISUlBX//+9+xbNkyHD58GNOmTcOoUaOwfft2pcwLL7yABQsWYO/evWjWrBmGDBkCu90OwBVshg0bhuHDh+OHH37AvHnzMHv2bHz00UfK+aNHj8Y///lPLFq0CEeOHMF7772HgIAAr3r88Y9/xIIFC7Bv3z4YDAY8/vjj9XL/RFS7+LJaImrwrFYrgoODsWXLFsTFxSn7J0yYgOLiYkycOBH9+vXDqlWrkJSUBADIzc1Fq1at8NFHH2HYsGEYOXIkLl26hP/+97/K+X/4wx/w+eef4/Dhwzh+/Djat2+P1NRUxMfHV6rDV199hX79+mHLli3o378/AGDTpk0YPHgwSkpKYDab6/gpEFFtYgsSETV4J0+eRHFxMe677z4EBAQo29///nf8+OOPSrny4Sk4OBjt27fHkSNHAABHjhzB3Xff7XXdu+++GydOnIDT6cTBgweh1+vRt2/f69alS5cuyvfNmzcHAGRnZ9/0PRJR/TKoXQEioptVWFgIAPj888/RsmVLr2Mmk8krJNWUr69vtcr5+Pgo30uSBMA1PoqIGha2IBFRg9epUyeYTCacPXsWbdu29doiIyOVcrt27VK+v3LlCo4fP46OHTsCADp27IgdO3Z4XXfHjh244447oNfrER0dDVmWvcY0EdGtiy1IRNTgNWnSBNOnT8e0adMgyzLuuece5OXlYceOHQgMDMRtt90GAHjllVcQEhKC8PBw/PGPf0RoaCgSExMBAM8//zx69uyJV199FUlJSUhPT8fixYvx17/+FQAQFRWFMWPG4PHHH8eiRYvQtWtXnDlzBtnZ2Rg2bJhat05EdYQBiYhuCa+++iqaNWuGlJQU/PTTT7BYLOjWrRtmzZqldHHNnz8fU6ZMwYkTJxATE4PPPvsMRqMRANCtWzf861//wpw5c/Dqq6+iefPmeOWVVzB27FjlM5YuXYpZs2bhmWeeweXLl9G6dWvMmjVLjdslojrGWWxEdMvzzDC7cuUKLBaL2tUhogaAY5CIiIiIKmBAIiIiIqqAXWxEREREFbAFiYiIiKgCBiQiIiKiChiQiIiIiCpgQCIiIiKqgAGJiIiIqAIGJCIiIqIKGJCIiIiIKmBAIiIiIqqAAYmIiIiogv8HschsccGpf70AAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history2.history['loss'])\n",
    "plt.plot(history2.history['val_loss'])\n",
    "plt.title('model 2 loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Для графика сверху пояснение***\n",
    "\n",
    "Гипотеза 1: увеличение сложности модели улучшит результат.\n",
    "\n",
    "Добавили второй скрытый слой в архитектуру нейронной сети. \n",
    "\n",
    "Функции потерь в данном случае уменьшаются и сильно коррелируют (накладываются друг на друга). Это свидетельствует о том, что либо модель обучилась хорошо, либо очень хорошо «заучила» тренировочные данные. Стоит отметить, что такой хороший результат на новых неизвестных данных модель может не показать. Для этой модели MAE = 0.04764918872152749, что как раз показывает, что на незнакомых данных модель работает не очень хорошо.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history3.history['loss'])\n",
    "plt.plot(history3.history['val_loss'])\n",
    "plt.title('model 3 loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Для графика сверху пояснение***\n",
    "\n",
    "Гипотеза 2: улучшение результата с помощью замены функции потерь на Huber Loss, которая представляет собой компромисс между MSE и MAE. Функция Huber Loss определяется параметром дельта (порог перехода от квадратичной к линейной функции). \n",
    "\n",
    "Функции потерь в данном случае начинают постепенно расходиться, что говорит о переобучении (возможно, выбрано слишком большое значение для дельта)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history4.history['loss'])\n",
    "plt.plot(history4.history['val_loss'])\n",
    "plt.title('model 4 loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Для графика сверху пояснение***\n",
    "\n",
    "Гипотеза 3: улучшение результата с помощью разделения данных на пакеты (батчи). В методе fit в библиотеке TensorFlow и Keras, параметр batch_size определяет размер пакета. Однако возникли резкие колебания графиков loss и val_loss. Поэтому было использовано drop_remainder=True для гарантии, что размер последнего пакета данных в эпохе будет равен указанному размеру пакета (аналог drop_last=True в PyTorch.). Это может предотвратить использование неполных пакетов данных, что делает обучение более стабильным. \n",
    "\n",
    "Функции потерь в данном случае накладываются, а MAE = 0.064. Следовательно, модель хорошо выучила тренировочные данные, а на незнакомых данных показала не очень хороший результат. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Оценка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "executionInfo": {
     "elapsed": 19,
     "status": "ok",
     "timestamp": 1636215168414,
     "user": {
      "displayName": "Mario Caesar",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GheyOtCjw9bQyrYjdnb46Fp9pWuEIUHVSHLqwMBBw=s64",
      "userId": "15479329890797732984"
     },
     "user_tz": -420
    },
    "id": "Xa5A1VSf4Fgu",
    "outputId": "8b03e79f-86a0-4abf-c15e-47db0f151b0c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "440/440 [==============================] - 0s 950us/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.050944746943429445\n"
     ]
    }
   ],
   "source": [
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print(mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Примеры результатов работы на test датасете:\n",
      "     Actual              Predicted\n",
      "0  0.043795  [0.03447765111923218]\n",
      "1  0.168208  [0.14804081618785858]\n",
      "2  0.036716  [0.02498193085193634]\n",
      "3  0.325513  [0.09480105340480804]\n",
      "4  0.086903  [0.03672991693019867]\n"
     ]
    }
   ],
   "source": [
    "# Преобразование массивов в одномерные списки\n",
    "y_test_list = y_test.tolist()\n",
    "y_pred_list = y_pred.tolist()\n",
    "\n",
    "# Создание DataFrame с фактическими и предсказанными значениями\n",
    "results_df = pd.DataFrame({'Actual': y_test_list, 'Predicted': y_pred_list})\n",
    "\n",
    "# Вывод нескольких примеров результатов\n",
    "print(\"Примеры результатов работы на test датасете:\")\n",
    "print(results_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "440/440 [==============================] - 1s 946us/step\n",
      "0.04764918872152749\n"
     ]
    }
   ],
   "source": [
    "y_pred2 = model2.predict(X_test)\n",
    "\n",
    "mae2 = mean_absolute_error(y_test, y_pred2)\n",
    "print(mae2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "440/440 [==============================] - 0s 922us/step\n",
      "0.06359520881310633\n"
     ]
    }
   ],
   "source": [
    "y_pred4 = model4.predict(X_test)\n",
    "\n",
    "mae4 = mean_absolute_error(y_test, y_pred4)\n",
    "print(mae4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
